{"name": "clef", "queries": [{"docid": "EP1688884A1", "paras": ["The present invention relates to an image correction apparatus and an image pickup apparatus for detecting a particular eye-related defect, such as red-eyes and gold-eyes, in an image, and correcting the defect.", "Traditionally, there has been known a camera provided with a flashing device with an emitting section which emits a flash. Eyes of persons and animals have a structure in which, at a dark place, pupils are opened large so that more light can be introduced thereinto. Therefore, when a person or animal with the pupils opened large is photographed at a dark place with the use of a flashing device provided for a camera, a flash emitted by the emitting section of the flashing device may enter the eyeballs through the widely opened pupils and reflected by capillaries of retinae covering the internal surface of the eyeballs, and as a result, a so-called red-eye phenomenon may be caused, in which the pupils of the person or animal are reproduced in red. There may also be a case where, when a picture is taken with the use of a flashing device provided for a camera, a so-called gold-eye phenomenon may be caused, in which pupils of a person or animal may be reproduced as whitish ones due to reflection of a flash by the sclerae or corneae covering the outermost layer of the eyeballs, depending on the incidence with which the flash emitted by the flashing device enters.", "With the recent development of digital processing techniques, there have been proposed an image processing apparatus or an electronic camera that acquires image data representing a picture in which the pupils of a person or animal are reproduced in red or reproduced as whitish ones, detects red-eye portions and gold-eye portions in an image represented by the acquired image data, and corrects the detected red-eye portions and gold-eye portions (see Patent Document: Japanese Patent Laid-Open No. 2000-305141 for example).", "The electronic camera proposed in the above-mentioned patent document, which focuses an image of a photographed object onto a charge coupled device (CCD) solid-state image pickup element to acquire image data representing the photographed object as a signal, is provided with a function of an image processing apparatus of detecting red-eye portions in an image of a photographed person or animal to correct the detected red-eye portions. Furthermore, the electronic camera proposed in the above-mentioned patent document is provided with an image display device for displaying an image, and there is displayed an image, in which eyes of a person or animal are reproduced as red-eyes, on the image display device when red-eye portions are detected. Based on the display, the user, such as the photographer of the image, confirms the red-eye portions in the image acquired by photographing and determines whether or not to correct the red-eye portions. When correction of the red-eye portions is specified as a result of the determination, there is displayed an image in which the red-eye portions have been corrected on the image display device, and thereby the user confirms whether or not the correction has been accurately performed.", "Thus, in the electronic camera proposed in the above-mentioned patent document, the user is required to perform confirmation twice, that is, when the red-eye portions have been detected and when the detected red-eye portions have been corrected. This is troublesome and time-consuming for the user.", "The screen of an image display device provided for an electronic camera is generally small. It is difficult to visually confirm red-eye portions using the image display device with such a small screen and the red-eye portions may be overlooked.", "As means for solving these problems, there is known means for facilitating visual confirmation of red-eye portions by zooming red-eye portions in an image displayed on the image display device. However, in the case of an image in which multiple eyes are reproduced as red-eyes, the confirmation work is troublesome.", "The above problems are not limited to the filed of cameras and photographs and are generally caused in the image processing field, for example, in the case of performing image processing for any image such as an image acquired from the Web.", "In consideration of the above situation, the object of the present invention is to provide an image correction apparatus and an image pickup apparatus that enable a particular eye-related defect, such as red-eye portions and gold-eye portions in an image, to be easily confirmed.", "A first image correction apparatus of the present invention to achieve the object is provided with:", "In the first image correction apparatus of the present invention, the number of positions at which a particular eye-related defect, such as red-eye portions and gold-eye portions, has been detected in an image is displayed together with the image before correction of the defect by the correction section, which includes the positions, or the image after correction of the defect by the correction section. Therefore, even in an image in which multiple eyes are reproduced as red-eyes, the defect can be easily confirmed without overlooking any defect position by referring to the displayed number of the positions.", "In the first image correction apparatus of the present invention, it is preferable that the correction section not only detects the defect in the image but also prioritizes the positions at which the defect has been found based on a predetermined criteria; and that the image display section, when displaying the image, displays in preference a position to which a higher priority has been given by the correction section.", "For example, by giving a higher priority to a photographed object located in the center of the angle of view or photographed with the face portion zoomed and giving a lower priority to other photographed objects, it is possible to confirm a main photographed object in preference and omit the confirming of unnecessary photographed objects such as passers-by.", "In the first image correction apparatus of the present invention, it is preferable that the image display section, when displaying the image, displays a list of the positions.", "The preferable image correction apparatus makes it possible to confirm the positions at which a defect has been found at a time.", "In the first image correction apparatus of the present invention, it is preferable that the image display section, when displaying the image, zooms at least one of the positions.", "If the number of positions in an image, at which a particular eye-related defect has been detected, is displayed together with the image in which at least one of the positions is zoomed as described above, the defect can be confirmed more easily.", "In the first image correction apparatus of the present invention, it is preferable that the image display section, when displaying the image, displays a normal image in which none of the positions is zoomed and a zoomed image in which one of the positions is zoomed.", "The preferable image correction apparatus makes it possible to confirm details and locations of the positions at which a defect has been detected while confirming the whole normal image.", "It is preferable that the first image correction apparatus of the present invention is provided with a confirmation section that receives an operation for confirming the positions in the image displayed by the image display section, at which the defect has been detected by the correction section; and that the image display section, when displaying the number of the positions, displays the number of the positions minus the number of positions confirmed by the confirmation section.", "The image correction apparatus provided with such a confirmation section in which the number of the positions minus the number of confirmed positions is displayed makes it possible, even if any position of the particular eye-related defect in the image is overlooked, to certainly confirm the defect by referring to the number of positions.", "In the first image correction apparatus of the present invention, it is more preferable that the correction section detects red-eye portions in the image and corrects the detected red-eye portions.", "Though a red-eye gives a psychologically uncomfortable feeling especially strongly among particular eye-related defects, they are difficult to visually recognize. Therefore, such an image correction apparatus that facilitates confirmation of correction of red-eye portions in an image is especially useful.", "In the first image correction apparatus of the invention, the image display section may display the number of eyes in which the defect has been detected by the correction section as the number of positions described above. Alternatively, the image display section may display the number of persons in which the defect has been detected by the correction section as the number of positions described above.", "A second image correction apparatus of the present invention to achieve the object is provided with:", "The second image correction apparatus of the present invention detects an eye-related defect in an image, corrects the detected defect and displays a corrected image in which the defect has been corrected. Therefore, the detected defect and the corrected defect can be confirmed with the use of the corrected image simultaneously at one time, and confirmation of the eye-related defect in the image can be realized by an easy operation.", "In the second image correction apparatus of the present invention, it is preferable that the correction section not only detects the defect in the image but also prioritizes the positions at which the defect has been found based on a predetermined criteria; and that the image display section, when displaying the corrected image, displays in preference a position to which a higher priority has been given by the correction section.", "For example, by giving a higher priority to a photographed object located in the center of the angle of view or photographed with the face portion zoomed and giving a lower priority to other photographed objects, it is possible to confirm a main photographed object in preference and omit the confirming of unnecessary photographed objects such as passers-by.", "In the second image correction apparatus of the present invention, it is preferable that the image display section, when displaying the corrected image, displays a list of the positions at which the defect has been detected by the correction section.", "By displaying the list of the positions at which the defect has been detected, the positions at which the defect has been detected can be confirmed at a time.", "In the second image correction apparatus of the present invention, it is preferable that the image display section, when displaying the corrected image, displays a normal image in which none of the positions at which the defect has been detected by the correction section is zoomed and a zoomed image in which one of the positions is zoomed.", "The preferable image correction apparatus makes it possible to confirm details and locations of the positions at which a defect has been detected while confirming the whole normal image.", "It is preferable that the second image correction apparatus of the present invention is provided with a correction deletion section that restores the defect corrected by the correction section, in the corrected image displayed by the image display section, to the original condition held before the defect is corrected by the correction section.", "The image correction apparatus provided with such a correction deletion section can restore the corrected image to the original condition before a defect was corrected when detection or correction of the defect by the correction section is inappropriate.", "In the second image correction apparatus of the present invention, it is also preferable that the image display section, when displaying the corrected image, emphasizes the defect corrected by the correction section.", "If the eye-related defect in the corrected image is emphasized, the eye-related defect in the image can be confirmed more easily.", "In the second image correction apparatus of the present invention, it is more preferable that the correction section detects red-eye portions in the image and corrects the detected red-eye portions; and that the image display section, when the image data is acquired by the image acquisition section, displays a corrected image in which the red-eye portions have been corrected by the correction section.", "Though red-eye gives a psychologically uncoinfcrtable feeling especially strongly among particular eye-related defects, the red-eyes are difficult to visually recognize. Therefore, such an image correction apparatus that facilitates confirmation of correction of red-eye portions in an image is especially useful.", "A first image pickup apparatus of the present invention to achieve the object is:", "As described above, though the screen of an image display device provided for an image pickup apparatus is generally small. However, if the number of positions in a photographed object image at which a particular eye-related defect, such as red-eye portions and gold-eye portions, has been detected is displayed, together with the image before correction of the defect by the correction section, which includes the positions, or the image after correction of the defect by the correction section, as in the image pickup apparatus of the present invention, then, even in the case of an image in which multiple eyes are reproduced as red-eyes, it is possible to easily confirm the defect without overlooking any defect position by referring to the displayed number of the positions.", "In the first image pickup apparatus of the present invention, it is preferable that the image display section, when displaying the image, zooms at least one of the positions.", "It is also preferable that the first image pickup apparatus of the present invention is provided with a confirmation section that receives an operation for confirming the positions in the image displayed by the image display section, at which the defect has been detected by the correction section; and that the image display section, when displaying the number of the positions, displays the number of the positions minus the number of positions confirmed by the confirmation section.", "In the first image pickup apparatus of the present invention, it is more preferable that the correction section detects red-eye portions in the image and corrects the detected red-eye portions.", "Furthermore, in the first image pickup apparatus of the present invention, the image display section may display the number of eyes in which the defect has been detected by the correction section as the number of the positions described above. Alternatively, the image display section may display the number of persons in which the defect has been detected by the correction section as the number of positions described above.", "A second image pickup apparatus of the present invention to achieve the object is:", "As described above, the screen of an image display device provided for an image pickup apparatus is generally small. However, if an image pick apparatus detects an eye-related defect in a photographed object image, corrects the detected defect, and displays the image in which the defect has been corrected, as the second image pickup apparatus of the present invention, it is possible to confirm the detected defect and the corrected defect simultaneously at one time with the use of the corrected image. Furthermore, though operationality of switches provided for an image pickup apparatus are generally not good, red-eye portions are confirmed with the use of the corrected image in which the defect has been corrected, in the second image pickup apparatus of the present invention, and accordingly, the number of operations for confirmation is reduced, and therefore the defect in eyes in an image can be easily confirmed even with a low-operationality switch.", "In the second image pickup apparatus of the present invention, it is preferable that the correction section not only detects the defect in the image but also prioritizes the positions at which the defect has been found based on a predetermined criteria; and that the image display section, when displaying the corrected image, displays in preference a position to which a higher priority has been given by the correction section.", "By giving a priority to positions at which a defect has been found, it is possible to efficiently perform confirmation.", "In the second image pickup apparatus of the present invention, it is preferable that the image display section, when displaying the corrected image, displays a list of the positions at which the defect has been detected by the correction section.", "By displaying the list of positions at which the defect has been detected, it is possible to confirm the positions at which the defect has been detected at a time.", "In the second image pickup apparatus of the present invention it is preferable that the image display section, when displaying the corrected image, displays a normal image in which none of the positions at which the defect has been detected by the correction section is zoomed and a zoomed image in which at least one of the positions is zoomed.", "The preferred image pickup apparatus makes it possible to confirm the whole image by a normal image and details and locations of the positions at which a defect has been detected simultaneously at one time.", "It is preferable that the second image pickup apparatus of the present invention is provided with a correction cancellation section that restores the defect corrected by the correction section, in the corrected image displayed by the image display section, to the original condition held before the defect is corrected by the correction section depending on operations.", "The image pickup apparatus provided with such a correction cancellation section makes it possible, if detection or correction of a defect by the correction part is inappropriate, to restore the corrected defect to the original condition before correction of the defect.", "In the second image pickup apparatus of the present invention, it is preferable that the image display section, when displaying the corrected image, emphasizes the defect corrected by the correction section.", "If an eye-related defect in a corrected image is emphasized as described above, the eye-related defect in the image can be confirmed more easily.", "A third image pickup apparatus of the present invention to achieve the object is provided with:", "By making a presumption in advance on whether or not a particular eye-related defect will occur in a photographed object image, it is possible to certainly perform confirmation if it occurs and save the trouble of confirmation if it does not occur.", "It is preferable that the third image pickup apparatus of the present invention is further provided with a flash emitting section that emits a flash in synchronization with photographing performed by the image pickup section; and a control section that controls emission performed by the flash emitting section based on the result of the presumption by the presumption section.", "When it is presumed that a particular defect will occur in an image to be photographed, occurrence of the defect can be reduced by, for example, adjusting the emission strength of the flash emitting section.", "It is also preferable that the third image pickup apparatus of the present invention is further provided with a correction section that detects the particular eye-related defect in the photographed object image and corrects the detected defect when it is presumed by the presumption section that the defect is to occur.", "When it is presumed that a defect will occur in a photographed image, it is possible to acquire a visually desirable image having no defects has not occurred by detecting and correcting the defect in the photographed object image.", "Alternatively, it is preferable that the third image pickup apparatus of the present invention is further provided with a warning section that issues a warning indicating that the defect is to occur when it is presumed by the presumption section that the defect is to occur.", "By receiving a warning indicating that a defect will occur, a photographer can prevent the defect from occurring by, for example, changing the distance to the object to be photographed when photographing the object.", "It is also preferable that the third image pickup apparatus of the present invention is further provided with a flash emitting section that emits a flash; the image pickup section acquires first image data by avoiding the flash emitted by the flash emitting section and acquires second image data in synchronization with the flash emitted by the flash emitting section; and that the presumption section is provided with a defect detection section that compares colors in a first image represented by the first image data and colors in a second image represented by the second image data and considers the defect to have occurred at positions at which the colors are different to the degree equal to or exceeding a predetermined level.", "Particular eye-related defects, such as red-eyes, are usually caused by a flash emitted by the flash emitting section. Accordingly, by comparing colors in a first image acquired without a flash, in which the defect has not occurred, and colors in a second image acquired with a flash and considering that the defect has occurred at positions where the colors are different to the degree equal to or exceeding a predetermined level, it is possible to easily detect the defect in a photographed image.", "According to the present invention, there can be provided an image correction apparatus and an image pickup apparatus that enable easy confirmation of particular eye-related defects such as red-eyes and gold-eyes in an image.", "Embodiments according to the present invention will be described below.", "There will be described embodiments wherein the present invention is applied to an electronic camera in which an image of a photographed object is focused on a charge coupled device (CCD) solid-state image pickup element to acquire image data representing the photographed object as a signal.", "Fig. 1 is an external perspective view of an electronic camera according to one embodiment of the present invention when it is seen obliquely downwardly from the front. A general configuration of an electronic camera will be described first with reference to Figs. 1 to 3. An electronic camera according to this embodiment as the present invention is characterized in the processing operation in a \"first automatic red-eye correction processing\" mode and a \"second automatic red-eye correction processing\" mode, which is to be described later in detail.", "A camera 100 shown in Fig. 1 is a camera for photographing a picture onto a photograph film not shown.", "At the front of the camera 100, there is provided a lens barrel 101 with an image taking lens 101a provided therein. The image taking lens 101a focuses the light of a photographed object incident thereto, onto the photographing surface of a CCD solid-state image pickup element (not shown) arranged inside the camera, and image data representing the photographed object is generated by the CCD solid-state image pickup element.", "At the front of the camera 100, there are provided a flash emitting device 103, a dimming sensor 102 for measuring the quantity of light emitted by the flash emitting device 103, a self timer LED 115 for lighting up to inform start of photographing to an object to be photographed, and an optical finder objective window 104a to be looked into by a photographer to determine the position of the object to be photographed. The flash emitting device 103 is an example of a flash emitting section according to the present invention.", "At the right end on the upper surface of the camera 100, there is provided a shutter release button 105 to be pressed down when performing photographing. A photographing mode dial 112 provided at the upper part of the back surface will be described with reference to Fig. 2.", "At the lower part of the left side surface of the camera 100, there are provided a universal serial bus (USB) terminal 106 into which a USB cable used for sending image data acquired by photographing to a personal computer is connected, and a power source input terminal 107 into which a power source cable used for supplying an external power to the camera 100 in that order from above.", "Fig. 2 is an external perspective view of the camera shown in Fig. 1 when it is seen obliquely downwardly from the back.", "At the back surface of the camera 100, there are provided an optical finder eyepiece window 104b, a liquid crystal display (LCD) panel 108 for displaying image and a date and time, a LCD panel activation button 109 for turning on/off image display on the LCD panel 108, a cross key 110 to be operated when selecting a variation or zooming, a menu/OK switch 111 to be used when displaying a menu for setting, for example, a date or a date and time on the LCD panel 108 or determining the setting of the menu, a cancellation switch 116 to be used when canceling the setting changed by various operations, the photographing mode dial 112 to be used when selecting various modes, which will be described later, a function selection lever 113 to be used when selecting either a \"photographing record\" function for photographing or an \"image data reproduction\" function for reproducing image data photographed and recorded, and a main switch 114 provided on the shaft of the function selection lever 113. In the camera 100, a \"first automatic red-eye correction processing\" mode or a \"second automatic red-eye correction processing\" mode can be selected based on the operation of the cross key 110, in which a red-eye portion in a photographed object image is detected and the detected red-eye portion is corrected. The \"first automatic red-eye correction processing\" mode and the \"second automatic red-eye correction processing\" mode will be described in detail later. The LCD panel 108 is an example of each of an image display section and a warning section according to the present invention.", "In the camera 100, the \"photographing record\" function is selected by moving the function selection lever 113 to the \"photographing record\" side 113a, and the \"image data reproduction\" function is selected by moving the function selection lever 113 to the \"image data preproduction\" side 113b. When the \"photographing record\" function is selected by the function selection lever 113, any of the followings can be selected by turning the photographing mode dial 112: a \"person photographing\" mode suitable for photographing a person, a \"scenery photographing\" mode suitable for photographing scenery, a \"sports\" mode suitable for photographing an object moving fast, a \"self timer\" mode that gives time difference after the shutter release button 105 is pressed down until photographing is actually performed, and a \"self photographing\" mode suitable for photographing the photographer himself. When no mode is selected, the \"person photographing\" mode is regarded as being selected when photographing is performed.", "Fig. 3 is a configuration block diagram of a signal processing section arranged inside the camera shown in Figs. 1 and 2.", "The configuration of the signal processing section arranged in the camera 100 will be now described with reference to the configuration block diagram shown in Fig. 3.", "All processings are controlled by a CPU 211 in the camera 100 shown in Figs. 1 and 2. The CPU 211 is an example of each of a photographing condition acquisition section and a control section according to the present invention.", "Description will be made on various switches first.", "The shutter release button 105 (see Figs. 1 and 2) which directs start of photographing is provided with a shutter switch 105a which operates in synchronization with the shutter release button 105 being pressed down. An on/off signal of the shutter switch 105a is inputted into the CPU 211. The CPU 211 receives the on signal of the shutter switch 105a as a signal of starting photographing. At this point of time, the function selection lever 113 has been shifted to the \"photographing record\" side 113a and it has been detected by the CPU 211 that photographing is to be performed.", "Any one of multiple items in a selection menu displayed on the LCD panel 108 can be selected with the cross key 110. Fig. 3 shows contact points 1101 to 1104 of the cross key 110. For example, when the contact point 1101 is pressed down, the cursor moves upward. When the contact point 1102 is pressed down, the cursor moves to the right. When any of the contact points 1101 to 1104 is connected and an on/off signal is inputted into the CPU 211, the CPU 211, based on the movement direction, transfers a direction to move the cursor to the LCD panel 108 via a bus 220. The cursor then moves to any of the displayed multiple items. Thus, the user can select any of the multiple items in the selection menu with the cross key 110 based on the cursor displayed on the LCD panel 108. In this case, if electronic zooming is selected, a partial area within the angle of view is cut out and electronically zoomed, with the center of the object to be photographed as the center for the cutting-out and zooming. It is also possible to specify the size of the area to be cut out.", "When the function selection lever 113 is shifted to the \"image data production\" side 113b, reproduction from a recording medium 240 is performed. In this case, even if a signal to direct photographing is inputted from the shutter switch 105a and the like, no processing is performed.", "Description will be now made on various elements other than the switches.", "In addition to the various switches described above, the flash emitting device 103 shown in Fig. 1, a timing generator 212, a motor driver 217 for driving a focus lens 216, a motor driver 214 for driving a motor provided in a light quantity adjustment device 300, and a CDSAMP 213 are connected to the CPU 211.", "When the user performs photographing, an image of an object to be photographed is displayed on the LCD panel 108 as it is moving. Watching the image of the object to be photographed, the user performs framing and presses the shutter release button 105 to perform photographing. In this case, by the shutter switch 105a, which operates in synchronization with the shutter release button 105, being turned on, the CPU 211 recognizes that a direction to start photographing has been sent by the user. In response to this, the CPU 211 outputs a signal to direct emission to the flash emitting device 103 and outputs a signal to direct start of photographing to the timing generator 212. The flash emitting device 103 emits a flash in response to the emission direction. Receiving the direction to start photographing, the timing generator 212 supplies a signal to a CCD solid-state image pickup element 210, informing that the shutter release button 105 has been pressed down. Receiving this signal, the CCD solid-state image pickup element 210 outputs image data photographed by the CCD solid-state image pickup element 210 when the shutter release button 105 was pressed down as an RGB signal. The RGB signal read from the CCD solid-state image pickup element 210 includes a lot of noises, and therefore the CPU 211 also outputs a timing signal for performing a noise reduction processing to the CDSAMP 213 in order to reduce the noises.", "There have been described signals outputted by the CPU 211 in response to an input signal from the various switches shown in Figs. 1 and 2.", "It will be now described how a photographing signal photographed by the CCD solid-state image pickup element 210 is processed in the order of steps.", "Description will be made on the case where the shutter release button 105 is pressed down when the function selection lever 113 shown in Fig. 2 is on the \"photographing record\" side 113a.", "When the function selection lever 113 connected to the CPU 211 is on the \"photographing record\" side 113a, if the shutter release button 105 is pressed down, the shutter switch 105a is connected and the CPU 211 detects that the shutter release button 105 has been pressed down. In this way, when the user presses down the shutter release button 105, the CPU 211 directs the timing generator 212 to start photographing. Receiving the starting direction, the CCD solid-state image pickup element 210 outputs an RGB signal.", "Even when the shutter release button is not pressed down, there is always displayed an object at which the image taking lens is pointed, on the LCD panel 108 of an image display device 227. The displayed object is.acquired by converting image data consisting of an RGB signal, which is read from the CCD solid-state image pickup element 210 at predetermined time intervals, into a YC signal by the image signal processing circuit 222 and supplying the YC signal to the image display device 227 via a video encoder 226. While such an object image is displayed, exposure is continuously adjusted by an AE & AWB detection circuit 231 and contrast is continuously detected by an AF detection circuit 230. The image signal processing circuit 222 is an example of the function of a correction section, a correction cancellation section and a confirmation section according to the present invention, and detects and corrects red-eye portions in a photographed image when photographing is performed, as described later. The combination of the CPU 211 and the image signal processing circuit 222 is an example of each of a presumption section and a defect detection section according to the present invention.", "As for exposure adjustment, exposure is adjusted by the AE & AWB detection circuit 231 based on brightness information in the RGB signal read from the CCD solid-state image pickup element 210 at predetermined time intervals. When exposure is adjusted by the AE & AWB detection circuit 231, the result is sent to the CPU 211. The CPU 211 gives a direction to the motor driver 214 based on the result, and the motor provided in the light quantity adjustment device 300 is driven so that the quantity of light required for appropriate exposure can be obtained. (Hereinafter, the series of processings beginning with the acquisition of the brightness information until the light quantity adjustment device 300 is adjusted to an appropriate exposure is referred to as an exposure processing.) As for focus adjustment, the focus lens 216 is moved by the AF detection circuit 230 and contrast of the RGB signal is detected by the AF detection circuit 230 at predetermined time intervals to perform focus adjustment. When contrast is detected by the AF detection circuit 230, the result is sent to the CPU 211. The CPU 211 directs the motor driver 217 to drive the focus lens 216 based on the result, and the focus lens 216 is driven to the focused position at which the detected contrast is maximized. (Hereinafter, the series of processings beginning with the detection of contrast until the focus lens 216 is arranged at the focused position is referred to as a focusing processing.) When the focus lens 216 is arranged at the focused position, the CPU 211 supplies an image acquisition signal to the timing generator 212, the timing generator 212 supplies a photographing start signal to the CCD solid-state image pickup element 210, and electric charge accumulated in the CCD solid-state image pickup element 210 is read on the side of the CDSAMP 213 as an RGB signal in response to a read signal of the timing generator 212.", "At the CDSAMP 213 to which the read RGB signal has been supplied, a noise reduction processing is performed, and the noise-reduced RGB signal is supplied to an A/D conversion circuit 218. At the A/D conversion circuit 218, the analog RGB signal is A/D converted into a digital RGB signal.", "The CPU 211 is connected with an image input controller 219, a memory (SDRAM) 221, the image signal processing circuit 222, a compression processing circuit 223, a medium controller 224, a USB controller 225, the video encoder 226, the AF detection circuit 230 and the AE & AWB detection circuit 231 via the bus 220, and addresses and data are sent and received via the bus 220. There are provided various registers for sending and receiving data via the bus 220, in the CPU 211, and the contents of these registers are rewritten as the processing by each processing section progresses. The CPU 211 reads the contents of the registers and performs processings.", "The RGB signal converted into a digital signal is led to the bus 220 by the image input controller 219, controlled by the CPU 211, and written in the memory (SDRAM) 221. The image input controller 219 is an example of an image acquisition section of the present invention. When acquisition of the RGB signal is completed, the RGB signal is then read from the memory (SDRAM) 221 and supplied to the image signal processing circuit 222 via the bus 220. At the image signal processing circuit 222, the RGB signal is converted into a YC signal, and image data compressed by the compression processing circuit 223 is recorded into the recording medium 240 as a JPEG file via the medium controller 224.", "The camera shown in Figs. 1 and 2 is also provided with the USB controller 225 and configured to be connectable with USB-based external equipment.", "There has been described a flow of image data until it is recorded to the recording medium 240 when photographing is performed in the camera 100 shown in Figs. 1 and 2.", "Fig. 4 is a flowchart showing an operational flow when a \"first automatic red-eye correction processing\" mode is selected.", "First, by selecting the \"photographing record\" function by moving the function selection lever 113 shown in Fig. 2 to the \"photographing record\" side 113a, selecting a desired photographing mode by turning the photographing mode dial 112, selecting the \"first automatic red-eye correction processing\" mode based on the operation with the cross key 110; and then pressing down the shutter release button 105, photographing is performed (step S101).", "Fig. 5 shows an example of an image photographed at step S101.", "There is shown an example of a photographed image with three persons 410, 420 and 430, which has been photographed by selecting the \"person photographing\" mode with the photographing mode dial 112 shown in Fig. 2, selecting the \"first automatic red-eye correction processing\" mode based on the operation with the cross key 110, and then pressing down the shutter release button 105.", "Since the \"first automatic red-eye correction processing\" mode is selected based on the operation with the cross key 110 shown in Fig. 2, an automatic red-eye correction processing is started for detecting red-eye portions in the image photographed and acquired at step S101 and correcting the detected red-eye portions (step S102).", "If red-eye portions have been detected as a result of the detection of red-eye portions in the photographed image performed at step S102 (step S103: YES), then the number of unconfirmed positions, which is the number of persons who have not been confirmed by a confirmation operation to be described later, among the persons on which a red-eye portion has been detected, is displayed together with a red-eye corrected image for which the automatic red-eye correction processing has been performed on the LCD panel 108 shown in Fig. 2 (step S104). In this case, the number of unconfirmed positions is an example of the number of positions according to the present invention.", "If there is no red-eye portion detected in the detection of red-eye portions in the photographed image performed at step S102 (step S103: NO), then image data representing the photographed image is recorded to the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S112).", "Fig. 6 shows a display example wherein there are displayed a red-eye corrected image for which the automatic red-eye correction processing has been performed at step S104 and the number of unconfirmed positions on a LCD panel.", "There is shown an example wherein a red-eye corrected image acquired after the automatic red-eye correction processing has been performed for the photographed image shown in Fig. 5 is displayed on the LCD panel 108 shown in Fig. 2, with the faces 411a, 421a and 431a of the three persons 411, 421 and 431, which have been corrected by the automatic red-eye correction processing, enclosed with a continuous circle 510, 520 and 530 for emphasis, and at the upper left of the LCD panel 108, the number of unconfirmed positions 610 is displayed, which is the number of persons who have not been confirmed by a confirmation operation to be described later, among the persons on which a red-eye portion has been detected. In the example shown in Fig. 6, \"3\" is displayed as the number of unconfirmed positions 610 at the upper left of the LCD panel 108, indicating that a red-eye portion has been detected and corrected for all the three persons 411, 421 and 431.", "Fig. 7 shows display examples different from Fig. 6, wherein there are displayed a red-eye corrected image and the number of unconfirmed positions.", "Though the number of unconfirmed positions 610 in Fig. 6 is expressed in a figure, the number of unconfirmed positions 611 shown in Part (A) of Fig. 7 is expressed as a bar, and the number of unconfirmed positions 612 shown in Part (B) is expressed as the number of dots. The number of unconfirmed positions can be expressed by means other than using a figure.", "If the number of unconfirmed positions at which a red-eye portion has been detected but not confirmed is displayed together with the red-eye corrected image as described above, it is possible to easily confirm the red-eye portions without overlooking any red-eye portion even in the case of an image in which eyes of multiple persons are reproduced in red as shown in Fig. 6 by referring to the displayed number of unconfirmed positions. Furthermore, if faces with a red-eye portion in the red-eye corrected image are displayed in an emphasized condition, the red-eye portions in the red-eye corrected image can be confirmed more easily.", "If, as a result of the confirmation of the red-eye portion, with the use of the red-eye corrected image acquired after the automatic red-eye correction processing has been performed, at step S104, the user determines that the red-eye portion has been appropriately detected and corrected, then, by pressing down the menu/OK switch 111 shown in Fig. 2 (step S105: YES), image data representing the red-eye corrected image is recorded into the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S112).", "As described above, in the \"first automatic red-eye correction processing\" mode, after photographing has been performed by pressing down the shutter release button 105, confirmation of red-eye portions can be completed only by one operation of pressing down the menu/OK switch 111 at step S105. Thus, red-eye portions can be confirmed extremely easily.", "If, as a result of the confirmation of the red-eye portion, with the use of the red-eye corrected image acquired after the automatic red-eye correction has been performed, at step S104, the user desires to confirm a red-eye portion by zooming a person's face corrected by the automatic red-eye correction processing, then, by pressing down the cancellation switch 116 shown in Fig. 2 (step S105: NO), the face can be selected with the cross key 110 shown in Fig. 2 (step S106).", "Fig. 8 shows a display example wherein there is displayed a red-eye corrected image, on which a face can be selected with a cross key at step S106, on a LCD panel.", "Fig. 8 shows an example wherein a red-eye corrected image is displayed on the LCD panel 108 shown in Fig. 2, with the selected face 411a of the person 411 enclosed with a continuous-line circle 511 and with the faces 421a and 431a of the other persons 421 and 431, which can be selected with the cross key 110 shown in Fig. 2, enclosed with broken-line circles 521 and 531. The continuous-line circle 511 is moved to the face of another person based on the operation of the cross key 110 so that a desired face can be selected among the faces 411a, 421a and 431a of the persons 411, 421 and 431.", "Fig. 9 shows display examples different from Fig. 8 wherein there are displayed red-eye corrected images on which a face can be selected at step S106.", "In Part (A) of Fig. 9, there is shown a display example wherein faces 541, 542 and 543 corresponding to the faces 411a, 421a and 431a shown in Fig. 8, which can be selected with the cross key 110, are displayed as a list below the red-eye corrected image. In Part (B), there is shown a display example wherein only the faces 541, 542 and 543 are displayed as a list without display of the red-eye corrected image which is shown in Part (A). A pointer 540 is moved based on the operation of the cross key 110 so that a desired face can be selected among the faces 541, 542 and 543 displayed as a list. Thus, by displaying the faces 591, 542 and 543 corrected by the automatic red-eye correction processing as a list, the faces 541, 542 and 543 can be confirmed at a time. In this embodiment, description will be continued on the example wherein the red-eye corrected image is displayed as shown in Fig. 8 at step S106.", "After a desired person's face is selected based on the operation of the cross key 110 shown in Fig. 2, the selected person's face is zoomed on the LCD panel 108 shown in Fig. 2 by pressing down the menu/OK switch 111 (step S107).", "Fig. 10 shows a display example wherein a face zoomed at step S107 is displayed on a LCD panel.", "There is shown an example wherein, by selecting the face 411a of the person 411, which is enclosed with the continuous circle 510, in the red-eye corrected image shown in Fig. 8 and then pressing down the menu/OK switch 111, the face 411a is zoomed on the LCD panel 108 shown in Fig. 2.", "Fig. 11 shows display examples different from Fig. 10 wherein a zoomed face is displayed.", "In Part (A) of Fig. 11, the LCD panel 108 is divided into two areas 108_1 and 108_2. The red-eye corrected image is displayed in the first area 108_1 and the selected face 411a is zoomed in the second area 108_2. By displaying the red-eye corrected image and the zoomed face side by side as described above, it is possible to easily confirm the positions at which red-eye correction has been performed. When there are provided two or more LCD panels, a photographed image may be displayed on one panel 108A and a zoomed face on the other panel 108B as shown in Part (B). In this embodiment, description will be made on the example wherein the zoomed face is displayed in a display manner as shown in Fig. 10, at step S107.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the face zoomed at step S107, the user determines that the red-eye portion has been appropriately detected and corrected, then, by a confirmation operation of pressing down the menu/OK switch 111 shown in Fig. 2 (step S108: YES), the automatic red-eye correction processing for the red-eye portion in the zoomed face is determined. The process then returns to step S104, where the whole image is displayed on the LCD panel 108 shown in Fig. 2. Every time the confirmation operation of step S108 is performed, the number of unconfirmed positions displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions. After that, a person other than the person for whom the automatic red-eye correction processing has been determined can be selected according to the same procedure as described above.", "An electronic camera in which the number of unconfirmed positions minus the number of confirmed positions makes it possible to certainly confirm red-eye portions in a red-eye corrected image by referring to the number of unconfirmed positions even if any red-eye portion has been overlooked.", "If, as a result of the confirmation of the red-eye portions for which the automatic red-eye correction processing has been performed, with the use of the face zoomed at step S107, the user desires to further zoom the eye portion of the zoomed face for confirmation, then, by pressing down the cancellation switch 116 shown in Fig. 2 (step S108: NO), the zoomed eye portion is displayed on the LCD panel 108 shown in Fig. 2 (step S109).", "Fig. 12 shows a display example wherein an eye portion zoomed at step S109 is displayed on a LCD panel.", "There is shown an example wherein an eye portion 411b of the zoomed face 411a shown in Fig. 10 is zoomed on the LCD panel 108 shown in Fig. 2.", "Though, in this description of embodiments, cases wherein both eyes are zoomed have been described as an example of zooming an eye portion, one eye may be zoomed.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the eye portion zoomed at step S109, the user determines that the red-eye portion has been appropriately detected and corrected, then, by a confirmation operation of pressing down the menu/OK switch 111 shown in Fig. 2 (step S110: YES), the automatic red-eye correction processing for the red-eye portion of the zoomed face is determined. The process then returns to step S104, where the whole image is displayed on the LCD panel 108 shown in Fig. 2. Every time the confirmation operation of step S110 is performed, the number of unconfirmed positions displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions. After that, a person other than the person for whom the automatic red-eye correction processing has been determined can be selected according to the same procedure as described above.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the eye portion zoomed at step S109, the user determines that the red-eye portion has been inappropriately detected or corrected, then, by pressing down the cancellation switch 116 shown in Fig. 2 (step S110: NO), the detection or correction of the red-eye portion for the zoomed eye portion is cancelled (step S111). The process returns to step S104, where the whole image is displayed on the LCD panel 108 shown in Fig. 2. Every time the confirmation operation of step S111 is performed, the number of unconfirmed positions displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions. After that, a person other than the person for whom the automatic red-eye correction processing has been determined or cancelled can be selected according to the same procedure as described above.", "Though there have been described examples wherein detection or correction is canceled when the user determines that a red-eye portion has been inappropriately detected or corrected, the present invention is not limited thereto and the corrected red-eye portion may be manually re-corrected.", "In the processing mode described above, red-eye portions in a photographed image are detected; the detected red-eye portions are corrected; and a red-eye corrected image acquired after the red-eye portions are corrected is displayed. Therefore, the detected positions and the corrected result can be confirmed simultaneously at one time with the use of the red-eye corrected image. Furthermore, though operationality of switches provided for an electronic camera are generally not always good, red-eye portions are confirmed with the use of the corrected image acquired after the red-eye portions have been corrected in the electronic camera according to this embodiment, and accordingly the number of operations required for confirmation is reduced, and red-eye portions in an image can be easily confirmed even with a low-operationality switch.", "Fig. 13 is a flowchart showing an operational flow when a \"second automatic red-eye correction processing\" mode is selected.", "First, by selecting the \"photographing record\" function by moving the function selection lever 113 shown in Fig. 2 to the \"photographing record\" side 113a; selecting a desired photographing mode by turning the photographing mode dial 112; selecting the \"second automatic red-eye correction processing\" mode based on the operation with the cross key 110; and then pressing down the shutter release button 105, photographing is performed (step S201).", "When photographing is performed, the CPU 211 detects red-eye portions in a photographed image acquired by photographing at step S201 since the \"second automatic red-eye correction processing\" mode is selected based on the operation with the cross key 110 shown in Fig. 2. The CPU then starts the automatic red-eye correction processing for correcting the detected red-eye portions (step S202).", "If red-eye portions have been detected at the detection of red-eyes in the photographed image at step S202 (step S203: YES), the number of persons on whom a red portion has been detected (hereinafter referred to as the number of detections) is displayed on the LCD panel 108 shown in Fig. 2 together with a red-eye corrected image acquired after the automatic red-eye correction processing has been performed (step S204).", "If there is no red-eye portion detected in the detection of red-eye portions in the photographed image performed at step S202 (step S203: NO), then image data representing the photographed image is recorded into the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S213).", "Fig. 14 shows a display example wherein there are displayed a red-eye corrected image for which automatic red-eye correction processing is performed at step S204 and the detected number on a LCD panel.", "There is shown an example wherein a red-eye corrected image acquired after the automatic red-eye correction processing has been performed for the photographed image identical to the photographed image shown in Fig. 5, which has been acquired by photographing the three persons 410, 420 and 430 at step S201, is displayed on the LCD panel 108 shown in Fig. 2, with the faces 411a, 421a and 431a of the three persons 411, 421 and 431, which have been corrected by the automatic red-eye correction processing, enclosed with continuous circles 510, 520 and 530 for emphasis, and at the upper left of the LCD panel 108, the number of detections 620 is displayed, which is the number of detected red-eye portions. In the example shown in Fig. 14, \"3\" is displayed as the number of detections 620 at the upper left of the LCD panel 108, indicating that a red-eye portion has been detected and corrected for all the three persons 411, 421 and 431.", "If the number of detections which is the number of detected red-eye portions in a red-eye corrected image is displayed together with the red-eye corrected image as described above, it is possible to easily confirm the red-eye portions without overlooking any red-eye portion even in the case of an image in which eyes of multiple persons are reproduced in red as shown in Fig. 14 by referring to the displayed number of detected positions. Furthermore, if faces with a red-eye portion in the red-eye corrected image is displayed in an emphasized condition, the red-eye portions in the red-eye corrected image can be confirmed more easily.", "The CPU 211 then prioritizes the red-eye portions for which the automatic red-eye correction processing has been performed at step S202. In this embodiment, a \"red-eye portion closer to the center of the angle of view\" is given a higher priority first, and then a \"red-eye portion with a larger area\" is given a higher priority (step S205).", "If, after the confirmation of the red-eye portions, with the use of the red-eye corrected image acquired after the automatic red-eye correction processing has been performed, at step S204, the user does not perform confirmation of the red-eye portions with the use of an image displaying a zoomed face or eye-portion, which is to be described later, then, by pressing down the cancellation switch 116 shown in Fig. 2 (step S206: NO), image data representing the red-eye corrected image is recorded into the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S213).", "As described above, in the \"second automatic red-eye correction processing\" mode, after photographing has been performed by pressing down the shutter release button 105, confirmation of red-eye portions can be completed only by one operation of pressing down the cancellation switch 116 at step S206. Thus, confirmation of red-eye portions can be performed very easily.", "If, as a result of the confirmation of the red-eye portions, with the use of the red-eye corrected image acquired after the automatic red-eye correction processing has been performed, at step S204, the user desires to confirm a red-eye portion by zooming the face of a person corrected by the automatic red-eye correction processing, then, by pressing down the menu/OK switch 111 shown in Fig. 2 (step S206: YES), the face of a person with a red-eye portion, which has been given the highest priority at step S205, among the persons displayed with their faces enclosed with a continuous circle for emphasis at step S204, is zoomed on the LCD panel 108 shown in Fig. 2 together with the number of unconfirmed positions (step S207). The number of unconfirmed positions here is the number of the persons who have not been confirmed by a confirmation operation to be described later, among the persons on which a red-eye portion has been detected, similarly to the number of unconfirmed positions explained in the description of the \"first automatic red-eye correction processing\" mode, and this number of unconfirmed positions is also an example of the number of positions according to the present invention.", "An electronic camera in which the number of unconfirmed positions minus the number of confirmed positions is displayed makes it possible to certainly confirm red-eye portions in a red-eye corrected image by referring to the number of unconfirmed positions even when any red-eye portion has been overlooked.", "Fig. 15 shows a display example wherein a face zoomed at step S207 and the number of unconfirmed positions are displayed on a LCD panel.", "There is shown an example wherein the face 411a of the person 411, among the persons 411, 421 and 431 with their faces 411a, 421a and 431a enclosed with continuous circles 510, 520 and 530 in red-eye corrected images shown in Fig. 14, is zoomed on the LCD panel 108 shown in Fig. 2, and at the upper left of the LCD panel 108, the number of unconfirmed positions 610, which is the number of persons who have not been confirmed by a confirmation operation to be described later, among the persons on which a red-eye portion has been detected, is displayed.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the face zoomed at step S207, the user determines that the red-eye portion has been appropriately detected and corrected, then, by pressing down the menu/OK switch 111 shown in Fig. 2 (step S208: YES), the automatic red-eye correction processing for the red-eye portion in the zoomed face is determined. If there is any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom the automatic red-eye correction has been determined (step S212: YES), then the face of a person with a red-eye portion with the highest priority among the persons except for the person for whom the automatic red-eye correction processing has been determined is zoomed on the LCD panel 108 shown in Fig. 2 (step S207). Every time the confirmation operation of step S208 is performed, the number of unconfirmed positions 610 displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions.", "If there is not any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom the automatic red-eye correction processing for the red-eye portion in the face zoomed is determined in response to the YES operation at S208 or canceled by a \"result cancellation\" mode, which is to be described later (step S212: NO), then image data representing the red-eye corrected image determined by the YES operation at step S208 or canceled by the \"result cancellation\" mode to be described later is recorded into the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S213).", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the face zoomed at step S207, the user desires to further zoom the eye portion of the zoomed face for confirmation, then, by pressing down the cancellation switch 116 shown in Fig. 2 (step S208: NO), the zoomed eye portion is displayed on the LCD panel 108 shown in Fig. 2 together with the number of unconfirmed positions (step S209).", "Fig. 16 shows a display example wherein an eye portion zoomed at S209 and the number of unconfirmed positions are displayed on a LCD panel.", "There is shown an example wherein the eye portion 411b of the zoomed face 411a shown in Fig. 15 is zoomed on the LCD panel 108 shown in Fig. 2, and at the upper left of the LCD panel 108, the number of unconfirmed positions 610 is displayed, which is the number of persons who have not been confirmed by a confirmation operation to be described later, among the persons on which a red-eye portion has been detected.", "Though, in this description of the embodiments, cases wherein both eyes are zoomed have been described as an example of zooming an eye portion, one eye may be zoomed.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the eye portion zoomed at step S209, the user determines that the red-eye portion has been appropriately detected and corrected, then, by a confirmation operation of pressing down the menu/OK switch 111 shown in Fig. 2 (step S210: YES), the automatic red-eye correction processing for the red-eye portion of the zoomed face is determined. If there is any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom the automatic red-eye correction has been determined (step S212: YES), then the face of a person with a red-eye portion with the highest priority among the persons except for the person for whom the automatic red-eye correction processing has been determined is zoomed on the LCD panel 108 shown in Fig. 2 (step S207). Every time the confirmation operation of step S210 is performed, the number of unconfirmed positions 610 displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions.", "If there is not any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom the automatic red-eye correction processing for the red-eye portion in the face zoomed is determined in response to the YES operation at S210 or canceled by the \"result cancellation\" mode, which is to be described later (step S212: NO), then image data representing the red-eye corrected image determined by the YES operation at step S210 or canceled by the \"result cancellation\" mode to be described later is recorded into the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S213).", "The smaller the number of unconfirmed positions becomes, the lower the priority of the red-eye portion in the zoomed face of a person is. Therefore, if it is determined that the red-eye portion in the zoomed face is no more important after repeating the series of processings from step S207 to step S212, then the user can proceed to step S213 from the step S212 to record the red-eye corrected image by pressing down the cancellation switch 116 shown in Fig. 2.", "If, as a result of the confirmation of the red-eye portion for which the automatic red-eye correction processing has been performed, with the use of the eye portion zoomed at step S209, the user determines that the red-eye portion has been inappropriately detected or corrected, then, the user presses down the cancellation switch 116 shown in Fig. 2 (step S210: NO)", "When selecting the \"second automatic red-eye correction processing\" mode for the camera 100 of this embodiment to perform photographing, it is assumed that either the \"result cancellation\" mode for canceling detection or correction of a red-eye portion in a zoomed eye portion or the \"correction\" mode for enabling manual re-correction of the red-portion in the zoomed eye has been selected and set in advance. When either mode is set in advance, pressing down the cancellation switch 116 as the NO operation at step S210 causes automatic shift to the mode set in advance.", "When the \"result cancellation\" mode is set, detection or correction of the red-eye portion in a zoomed eye is cancelled if the cancellation switch 116 is pressed down as the NO operation at step S210 (step S211). If there is any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom the automatic red-eye correction has been canceled (step S212: YES), then the face of a person with a red-eye portion with the highest priority among the persons except for the person for whom the automatic red-eye correction processing has been determined is zoomed on the LCD panel 108 shown in Fig. 2 (step S207). Every time the confirmation operation of step S211 is performed, the number of unconfirmed positions 610 displayed at the upper left of the LCD panel 108 minus 1 (one) is newly displayed as the number of unconfirmed positions.", "If the automatic red-eye correction processing for the red-eye portion in the zoomed face is cancelled at step S211, or if there is not any remaining person for whom the automatic red-eye correction processing has been performed and who was displayed at step S204 other than the person for whom determination has been performed by the confirmation operation described above (step S212: NO), then image data representing the red-eye corrected image cancelled at step S211 or determined by the confirmation operation described above is stored in the recording medium 240 as a JPEG file via the medium controller 224 shown in Fig. 3 (step S213).", "When the \"correction\" mode is selected, inappropriate detection or correction such as displacement and unsuitable size can be manually re-corrected by pressing down the cancellation switch 116 as the NO operation at step S210.", "In the first embodiment, there have been described examples wherein the red-eye correction processing and the work for confirming the processing is performed immediately after photographing. However, the series of processings including acquisition of a photographed image, red-eye correction processing and display of a corrected image may be performed for multiple photographed images and the work for confirming them may be collectively performed later, in an image correction apparatus and an image pickup apparatus of the present invention. When only the work of confirming the red-eye correction processing is performed for images collectively later, both of the original photographed images and corrected images for which the red-eye correction has been performed are stored, and unnecessary images are deleted after the confirmation work. In this case, only a part of an image, where a defect has occurred, may be stored instead of storing the whole image. Alternatively, correction information may be stored instead of an image. Having a smaller data size than an image, the correction information is advantageous in that it does not put much pressure on the capacity of a recording medium. As a method for storing the correction information, it is conceivable to embed the correction information into an eye portion where a defect has occurred as a tag information, into a margin portion where no image is arranged, or into the image as an electronic watermark.", "The description of the first embodiment according to the present invention has been completed. A second embodiment of the present invention will be now described. A camera of this embodiment has a configuration similar to that of the camera 100 of the first embodiment shown in Figs. 1 to 3. Figs. 1 to 3 are also used to describe this embodiment, and only differences from the first embodiment are described.", "Fig. 17 is a flowchart showing a series of processings from photographing of an object with a camera according to a second embodiment to storage of a photographed image.", "Similarly to the first embodiment, when the user adjusts the function selection lever 113 as shown in Fig. 2 to the \"photographing record\" side 113a first, a photographed object image is roughly read at predetermined time intervals by the CCD solid-state image pickup element 210 shown in Fig. 3, an RGB signal is outputted, and then the series of exposure processing and focusing processing are performed (pre-photographing at step S301).", "The operator selects a mode (\"person photographing\" mode, \"scenery photographing\" mode, \"sports\" mode, \"self timer\" mode and \"self photographing\" mode) using the photographing mode dial 112 shown in Fig. 2. Furthermore, when performing flash photographing accompanied by a flash, a flash button (not shown) is pressed down to specify flash photographing. The pressed down condition of the photographing mode dial 112 and the flash button is sent to the CPU 211.", "If the flash button is not pressed down (step S302: NO), then it is presumed that a red-eye defect will not occur in a photographed image in the CPU 211, and the process proceeds to step S311 from step S302 in the flowchart of Fig. 17.", "When the user presses down the shutter release button 105, the CPU 211 detects the shutter release button 105 being pressed down. The CPU 211 directs the timing generator 212 to start photographing and the photographed object image is read in detail by the CCD solid-state image pickup element 210 to perform the photographing processing similar to that performed at step S101 in Fig. 4 is performed (step S311).", "The image signal processing circuit 222 performs a predetermined image processing, such as a gradation correction processing, for image data acquired by photographing. The image data for which the image processing has been performed is recorded into the recording medium 240 (step S313 in Fig. 17). Since the image processing such as a gradation correction processing has been traditionally broadly performed, description thereof is omitted herein.", "Eye-related defects such as red-eyes usually do not occur easily when flash photographing is not performed. Accordingly, when flash photographing is not performed, it is possible to speed up processings by omitting the red-eye correction processing.", "If the user presses down the flash button (step S302: YES) and a mode other than the \"person photographing\" mode is selected (step S303: NO), then the CPU 211 also presumes that a red-eye defect will not occur in a photographed image, and the process then proceeds to step S311 from step S303 in the flowchart to perform photographing.", "If the user presses down the flash button (step S302: YES), the \"person photographing\" mode is selected (step S303: YES), and the distance to the vicinity of the center of the angle of view (distance to the object), which is calculated by the focusing processing during the pre-photographing at step S301, is beyond a predetermined range (step S304: NO), then the CPU 211 also presumes that a red-eye defect will not occur in a photographed image, and the process then proceeds to step S311 from step S304 in the flowchart to perform photographing.", "When the distance to the object is beyond a predetermined range, for example, when it is too short or too long, the possibility that a red-eye defect occurs is low even if there is a person in a photographed image. In this embodiment, when a mode other than the \"person photographing\" mode (\"scenery photographing\" mode, \"sports\" mode, \"self timer\" mode or \"self photographing\" mode) is selected as the mode, it is presumed that there is no person in a photographed image or that the distance to the object is beyond a predetermined range even if there is any person photographed, and therefore the red-eye correction processing is omitted. In this embodiment, the \"person photographing\" mode is initially selected. Therefore, if the user performs photographing without regard to the mode, the \"person photographing\" mode is selected (step S303: YES) and photographing that prevents red-eye defect from occurring, which will be described later, is performed. In the case of a camera for which a mode other than the \"person photographing\" mode is initially selected or a camera with an auto mode in which the camera automatically selects a suitable mode, if either the condition that \"'the person photographing' mode is selected (step S303)\" or the condition that \"the distance to the object is within a predetermined range (step S304)\" is true, then the process may proceed to the photographing process at and after step S305 for preventing a red-eye defect from occurring.", "If the user presses down the flash button (step S302: YES), the \"person photographing\" mode is selected as the mode (step S303: YES), and the distance to the object is within a predetermined range (step S304: YES), then the CPU 211 presumes that a red-eye defect will occur in a photographed image. In this case, the CPU 211 causes a warning to be disaplayed on the LCD panel 108 shown in Fig. 2, indicating that \"a red-eye will occur\" (step S305). By receiving the warning, the user can certainly recognize that \"a red-eye may occur\".", "Furthermore, the CPU 211 directs the flash emitting device 103 shown in Fig. 3 to adjust the emission strength and the emission period of the flash emitting device 103 to predetermined values at which a red-eye will not easily occur (step S306).", "When the flash emitting device 103 has been adjusted and the user presses down the shutter release button 105, the CPU 211 detects the shutter release button 105 being pressed down and performs a photographing processing accompanied by a flash (step S307). In image data acquired by the photographing process at step S307, red-eyes are prevented from occurring.", "The CPU 211 directs the CDSAMP 213 to adjust the gain of an amplifier (step S308).", "The image processing similar to that performed at step S312 is performed for the image data acquired by photographing (step S309), and the image data for which the image processing has been performed is recorded into the recording medium 240 (step S310) .", "By making a presumption on whether or not a defect such as red-eyes will occur in advance based on photographing conditions such as a photographing mode, with or without a flash, distance to the object and the like, and adjusting emission of the flash emitting device when it is presumed that a defect will occur, occurrence of red-eyes can be reduced.", "In this embodiment, occurrence of red-eyes is reduced and therefore confirmation of photographed images is not performed. However, if a warning is issued, confirmation may be performed to make sure.", "The description of the second embodiment according to the present invention has been completed. A third embodiment of the present invention will be now described. A camera of this embodiment also has a configuration similar to that of the camera 100 of the first embodiment shown in Figs. 1 to 3. Figs. 1 to 3 are also used to describe this embodiment, and only differences between the first and second embodiments are described.", "In the camera of this embodiment, the shutter release button 105 shown in Fig. 1 can be pressed down at two stages. By pressing the button at the first stage, the pre-photographing (the exposure processing and the focusing processing) is performed. By pressing the button at the second stage, the actual photographing processing is performed.", "Fig. 18 is a flowchart showing a series of processings from photographing of an object with a camera according to the third embodiment to storage of a photographed image.", "First, the user selects a mode (\"person photographing\" mode, \"scenery photographing\" mode, \"sports\" mode, \"self timer\" mode and \"self photographing\" mode) using the photographing mode dial 112 shown in Fig. 2. Furthermore, when performing flash photographing accompanied by a flash, the user presses down a flash button (not shown) to specify flash photographing. Furthermore, when performing the automatic red-eye correction processing, the user selects the \"automatic red-eye correction processing\" mode (for detecting red-eye portions in a photographed object image and correcting the detected red-eye portions) with the cross key 110. The setting condition of the cross key 110, the photographing mode dial 112 and the flash button is sent to the CPU 211.", "The user then points the camera to a desired object to be photographed and presses down the shutter release button 105 at the first stage (step S401).", "If flash photographing is not selected with the flash button (step S402 in Fig. 18: NO), the photographing processing not accompanied by a flash, similar to that performed at step S310 in Fig. 17, is performed (step S411), and image data acquired by the photographing processing is recorded into the recording medium 240 (step S410). Eye-related defects such as red-eyes seldom occur in an image photographed without a flash, and therefore the red-eye correction processing can be omitted.", "If flash photographing is selected with the flash button (step S402 in Fig. 18: YES), the pre-photographing similar to that performed at step S301 in Fig. 17 is performed inside the camera, and image data with rough pixels (hereinafter referred to as low-resolution data) is acquired without a flash from the flash emitting device 103 (step S403). This low-resolution data is an example of first image data according to the present invention, and a low-resolution image represented by the low resolution data is an example of a first image according to the present invention.", "The user then presses down the shutter release button 105 at the second stage to direct photographing (step S404).", "The photographing processing accompanied by a flash, similar to that performed at step S307 in Fig. 7, is performed inside the camera, and image data with fine pixels (hereinafter referred to as high-resolution data) is acquired (step S405.) The high-resolution data is an example of second resolution data according to the present invention, and a high-resolution image represented by the high-resolution data is an example of a second image according to the present invention.", "If the \"automatic red-eye correction processing\" mode is not selected (step S406: NO), the red-eye correction processing is not performed, and the acquired high-resolution data is recorded into the recording medium 240 (step S410).", "If the \"automatic red-eye correction processing\" mode is selected (step S406: YES), the image signal processing circuit 222 compares colors in the low-resolution image represented by the low-resolution data acquired at step S403 and colors in the high-resolution image represented by the high-resolution data acquired at step S405 (step S407). In this embodiment, hue difference between the high-resolution image and the low-resolution image is acquired by the image signal processing circuit 222.", "If the hue difference acquired at step S407 is below a predetermined value (step S408: NO), it is presumed that there is no red-eye caused in the high-resolution image, the high-resolution image data is recorded into the recording medium 240 without the red-eye correction processing being performed by the image signal processing circuit 222 (step S410). Since the low-resolution image has been acquired without a flash, the possibility of occurrence of red-eyes is low. On the other hand, the high-resolution image has been acquired with a flash, and therefore possibility of occurrence of red-eyes is high. However, the difference between the colors of the high-resolution image and those of the low-resolution image is below the predetermined value, it is determined that no red-eye has been occurred.", "If the hue difference acquired at step S407 is equal to or above the predetermined value (step S408: YES), the image signal processing circuit 222 considers that a defect has occurred at positions in the high-resolution image at which the hue difference is equal to or above the predetermined value. If the lightness difference at a position in the high-resolution image at which a defect has occurred is significantly different from that in the part around the position, the defect at the position can be considered to be a gold-eye defect, and the hue difference or the saturation difference at the position is significantly different from that in the part around the position, the defect at the position can be considered to be a red-eye defect.", "When a defect is detected, the automatic red-eye correction processing similar to that performed at step S102 in Fig. 4 is performed for the high-resolution data (step S409). After confirmation is performed for the red-eye portions, the image data for which the automatic red-eye correction processing has been performed is recorded into the recording medium 240 (step S410) .", "By performing the red-eye correction processing only when it is presumed in advance that a red-eye defect will occur in a photographed image, the burden of processing can be reduced and the confirmation work for red-eye corrected images can be also reduced.", "Though, this embodiment has been described with an example wherein the present invention is applied to an electronic camera in which an image of a photographed object is focused on a CCD solid-state image pickup element to acquire image data representing the photograph object as a signal, the present invention is not limited thereto. The present invention can also be applied to an image correction apparatus for detecting a particular eye-related defect in an image represented by acquired image data, correcting the detected defect and displaying the number of positions at which the defect has been detected together with the image including the positions, which is realized, for example, by a personal computer.", "Though, in this description of the embodiments, there have been shown examples wherein the automatic red-eye correction processing is performed in response to the \"first automatic red-eye correction processing\" mode or the \"second automatic red-eye correction processing\" mode being selected, the automatic red-eye correction processing may be always performed after photographing or after photographing with a flash.", "In the above description, there have been shown examples wherein the red-eye correction processing and the work for confirming the processing are performed immediately after photographing. However, in an image correction apparatus and an image pickup apparatus of the present invention, multiple photographed images may be acquired first, and the red-eye correction processing and the work for confirming the processing may be performed for the images collectively later. When only the work for confirming the red-eye correction processing is performed for images collectively, both of the original photographed images and corrected images for which the red-eye correction has been performed are stored and unnecessary images are deleted after the confirmation work. In this case, instead of storing the whole image, only a part of the image where a defect has occurred may be stored. Alternatively, correction information may be stored instead of an image.", "There was described an example wherein a warning to the effect that a defect will occur is displayed on the image display section. However, a warning according to the present invention may be displayed on a finder and the like which the user looks into.", "There was described an example wherein a warning to the effect that a defect will occur is displayed on an image display section. However, a warning according to the present invention may be issued by voice.", "There was described an example of a warning section for issuing a warning to the effect that a defect will occur. However, a warning section according to the present invention may issue a notification to the effect that the correction processing will work in conjunction with a photographing mode, for example, when the automatic red-eye correction processing mode is set, or may issue an advice to set the automatic red-eye correction processing mode when flash photographing is set without setting the automatic red-eye correction processing mode.", "There was described an example wherein a presumption is made on whether or not a defect has occurred in a photographed image based on difference between colors in a first image acquired without a flash and colors in a second image acquired with a flash. However, an image correction apparatus and an image pickup apparatus according to the present invention may emit a flash even during pre-photographing and detect red-eyes or issue a warning based on low-resolution data acquired by the pre-photographing. By detecting red-eyes with the use of low-resolution data acquired by pre-photographing, the processings are distributed and time required for the red-eye correction processing after actual photographing can be shortened.", "In this description of the embodiments, there have been described examples wherein red-eye portions in a photographed image are detected and the detected red-eye portions are corrected, the present invention is not limited thereto, and a particular eye-related defect, such as a gold-eye portion, may be detected and the detected defect may be corrected.", "In this description of the embodiments, \"the number of unconfirmed positions\" indicating the number of persons for whom a red-eye portion has been detected is shown as an example of \"the number of positions\". However, \"the number of positions\" according to the present invention may be, for example, the number of eyes for which a defect such as a red-eye portion has been detected.", "There was described an example wherein the number of positions at which a defect has been detected is displayed. However, an image display section according to the present invention may display, for each of levels of a defect, the number of positions at which the defect of the level has occurred.", "In this description of the embodiments, there have been used examles wherein the number of positions in a photographed image at which a red-portion has been detected is displayed together with a red-eye corrected image including the positions, which has been acquired after the red-eye portions in the photographed image have been detected and corrected. However, the present invention is not limited thereto, and the number of positions in a photographed image at which a red-eye portion has been detected may be displayed together with the photographed image including the positions, which has been acquired before the red-eye portions in the photographed image have been detected and corrected.", "Preferred Embodiments of the Invention are defined in paragraphs 1 to 21"], "tags": ["G06T"]}, {"docid": "EP1264835A1", "paras": ["Die vorliegende Erfindung betrifft metallorganische Verbindungen von \u00dcbergangsmetallen mit einem in 2-Position gebundenen und in 1,3-Position substituierten Indenyl-Liganden, ein Verfahren zu ihrer Herstellung und ihre Verwendung als Katalysatoren zur (Co)Polymerisation von olefinischen und/oder diolefinischen Monomeren.", "Entprechend der IUPAC-Nomenklatur werden die Positionen der Ringatome des Indens in der vorliegenden Anmeldung wie folgt bezeichnet:", "Die Herstellung von substituierten Indenen [Spaleck, W.; Rohrmann, J.; Antberg, M.; EP- A1-0 530 647] ist in der einschl\u00e4gigen Literatur bekannt und gelingt zum Beispiel ausgehend von 1-Indanonen [Smonou, I.; Ofranopopuolos, M. Synth. Commun. 1990, 20 (9), 1387].", "Die Synthese von 2-Bromindenen lehnt sich an bekannte Verfahren zu deren Herstellung an [Billups, W.; J. Org. Chem. 1980, 23, 4638; Porter, H.D.; Suter, C.M. J. Am. Chem. Soc. 1935, 57, 2022; Koelsch, C. J. Org. Chem. 1960, 25, 130; Wei\u00df, R.; Luft, S.; Monatsh. Chem. 1927, 48, 341].", "Stereorigide chirale Metallocene mit verbr\u00fcckten Indenylliganden als Katalysatoren zur Herstellung von Polyolefinen sind bekannt. Dabei hat sich erwiesen, dass Art und Position der Substituenten am Indenylanion und Art und Position der Verbr\u00fcckung einen Einflu\u00df sowohl auf die Katalysatoraktivit\u00e4t, als auch auf die Polymereigenschaften besitzt. Viele der Indenyl-Metallocene weisen eine Verbr\u00fcckung in 1-Position auf (1-Indenyl-Metallocene).", "Besondere Bedeutung besitzen die in 2 und/oder 4 Position substituierten Bis(1-indenyl)-Metallocene mit in 1-Position verbr\u00fcckten Indenylresten zur Herstellung von hochisotaktischem Polypropylen mit hoher Kristallinit\u00e4t und hohem Schmelzpunkt. (EP-A1-485 821, EP-A1-485 823, EP-A2-519237). Ebenso von Bedeutung sind die in 4,5-Position benzanellierten Bis(1-indenyl)-Metallocene (siehe Organometallics 1994, 13, 964-970).", "Es ist auch bekannt, metallorganische Verbindungen mit nur einem Indenylanion als Katalysatoren einzusetzen (Constrained Geometry Komplexe mit 1-Indenylliganden, siehe US-A-5, 026, 798, WO-97/15583-A1).", "Aus WO-94/11 406-A1 sind metallorganische Verbindungen von \u00dcbergangsmetallen bekannt, die einen Indenyl- und einen Cyclopentadienyl-Liganden aufweisen, wobei der Indenyl-Ligand in der 2-Position substituiert ist; dieser Substituent kann auch als Br\u00fccke zum 2. Liganden ausgebildet sein. Die Ausf\u00fchrungsbeispiele zeigen vielstufige Herstellungen mit \u00e4u\u00dferst unbefriedigenden Ausbeuten, die bei verbr\u00fcckten Verbindungen zu 1-Cyclopentadienyl-2-(2-indenyl)-ethan-zirkoniumchlorid, zu Bis-(2-indenyl)-methan-zirkoniumdichlorid oder zu Dimethyl-bis-(2-indenyl)-silan-zirkoniumdichlorid, welches noch Verunreinigungen enth\u00e4lt, f\u00fchren. In Organometallics 1993,", "In EP-A2-941 997 werden Ethylen-verbr\u00fcckte Bis(2-indenyl)zirkonocene offengelegt. Diese Zirkonocene werden zur Herstellung von speziellen Polyolefinen mit niedrigen Molekulargewichten eingesetzt.", "In EP-A1-0 940 408 werden silylverbr\u00fcckte 2-Indenyl-Metallocene und ein Verfahren zur Herstellung von metallorganischen Verbindungen mit einem in 2-Position gebundenen Indenyl-Liganden beschrieben.", "Des weiteren wird in US-A-5,504,169 ein Verfahren zur Herstellung von amorphen Polypropylenen mit einem Katalysatorsystem auf Basis von Monocyclopentadienyl-\u00dcbergangsmetallkomplexen beschrieben. Der am \u00dcbergangsmetallkomplex gebundene Cyclopentadienyl-Ring ist mit null, zwei oder vier Substituenten symmetrisch substituiert.", "\u00dcbergangsmetallkomplexe mit in 2-Position verbr\u00fcckten, 1,3-disubstituierten Indenyl-Liganden sind nicht bekannt.", "Es hat sich nun gezeigt, dass solche metallorganische Katalysatoren, deren Verbr\u00fcckung an der 2-Position mindestens eines 1,3-disubstituierten Indenylanions ansetzt, besondere Eigenschaften als Polymerisationskatalysatoren haben; sie erzeugen n\u00e4mlich bei der (Co)Polymerisation von \u03b1-Olefinen weitgehend ataktische Polymere mit hohen Molekulargewichten. Es war daher w\u00fcnschenswert, ein Herstellungsverfahren f\u00fcr solche in der 2-Position mindestens eines 1,3-disubstituierten Indenylanions verbr\u00fcckte Katalysatoren zu finden.", "Eine weitere Aufgabe bestand darin, einen Katalysator zur Verf\u00fcgung zu stellen, der f\u00fcr die Synthese von hochmolekularem EPDM geeignet ist.", "Die vorliegende Erfindung betrifft ein Verfahren zur Herstellung von metallorganischen Verbindungen von \u00dcbergangsmetallen mit in 1,3-Position substituierten 2-Indenyl Liganden, welche der allgemeinen Formel (I) entsprechen,", "Das Verfahren wird vorteilhaft bei Temperaturen im Bereich von -100 bis 120\u00b0C durchgef\u00fchrt.", "Als Metalle der Gruppen 1, 2 oder 12 seien insbesondere Lithium, Kalium, Natrium, Magnesium, Calcium, Zink, Cadmium und Quecksilber genannt. Bevorzugt werden die Metalle der Gruppen 2 und 12. Es kann auch vorteilhaft sein, die Metalle in einem Gemisch untereinander einzusetzen.", "Als entsprechende Metallverbindungen seien Butyl-Lithium, Butadien-Magnesium Anthracen-Magnesium sowie die entsprechenden Verbindungen der anderen genannten Metalle genannt.", "Es kann vorteilhaft sein, die nicht umgesetzten Metalle/Metallverbindungen vor Zugabe von (III) abzutrennen.", "In der Regel werden bei Umsetzung mit (III) die entsprechenden Metallhalogenide Metall Hal", "Weiterhin werden im Regelfall bei Zugabe von (Va) oder (Vb) die entsprechenden Verbindungen der Formeln", "Die Erfindung betrifft weiterhin die mit dem genannten Verfahren herstellbaren metallorganischen Verbindungen von \u00dcbergangsmetallen mit in 1,3-Position substituierten 2-Indenyl als Liganden, welche der allgemeinen Formel (I) entsprechen,", "Die Erfindung betrifft weiterhin die Verwendung der Verbindungen gem\u00e4\u00df Formel (I) als Katalysatoren sowohl auf einem Katalysatortr\u00e4ger (z.B. Al", "Die Erfindung betrifft in bevorzugter Weise das beschriebene Verfahren und die damit herstellbaren Verbindungen der Formel (I), worin Y die Bedeutung -Si(R", "Die Erfindung betrifft weiterhin Zwischenprodukte der Formel", "Cyclische \u03c0-Systeme im Rahmen der Bedeutung von Z sind beispielsweise substituiertes oder nicht substituiertes Cyclopentadien, substituiertes oder nicht substituiertes 1-Inden, substituiertes oder nicht substituiertes 2-Inden, substituiertes oder nicht substituiertes Fluoren, die mit der Br\u00fccke Y kovalent und mit M", "Die Erfindung betrifft in bevorzugter Weise das erfindungsgem\u00e4\u00dfe Verfahren und erfindungsgem\u00e4\u00dfe metallorganische Verbindungen von \u00dcbergangsmetallen der Formel (I), in der jedoch an die Stelle von Z das zweite Z' tritt, der die Bedeutung substituiertes oder nicht substituiertes Cyclopentadien, substituiertes oder nicht substituiertes 1-Inden, substituiertes oder nicht substituiertes 2-Inden, substituiertes oder nicht substituiertes Fluoren, -N(R", "Weiterhin bevorzugt sind solche mit der Formel Z\" mit dem Bedeutungsumfang von -N(R", "Geradkettiges oder verzweigtes C", "C", "C", "C", "C", "Aryl bzw. die aromatischen Anteile von Aralkyl k\u00f6nnen 1- oder 2-fach, gleich oder unterschiedlich durch Fluor, Chlor, Brom, Methyl, Ethyl, Methoxy oder Ethoxy substituiert sein.", "Q", "Halogen im Rahmen von R", "M", "X ist ein einfach oder mehrfach geladenes Anion aus der Gruppe von Fluorid, Chlorid, Bromid, C", "Hal", "Die Temperatur zur Umsetzung von (II) mit Mg oder Zn liegt im Bereich von -20\u00b0C bis +120\u00b0C, bevorzugt 0\u00b0C bis +100\u00b0C, besonders bevorzugt +25\u00b0C bis +80\u00b0C.", "Die Menge Mg bzw. Zn betr\u00e4gt 1 bis 100 Mol pro Mol (II). Grunds\u00e4tzlich kann auch mit Mengen au\u00dferhalb des genannten Bereiches gearbeitet werden. Unterhalb von 1 Mol Mg bzw. Zn pro Mol (II) ist die Umsetzung von (II) unvollst\u00e4ndig und oberhalb von 100 Mol ist kein weiterer Vorteil bez\u00fcglich Vollst\u00e4ndigkeit und Geschwindigkeit der Umsetzung zu erwarten. In bevorzugter Weise werden 1 bis 10 Mol Mg bzw. Zn, in besonders bevorzugter Weise 1 bis 5 Mol Mg bzw. Zn pro Mol (II) eingesetzt. Von den Metallen Mg und Zn ist Mg zur Umsetzung bevorzugt.", "Die Temperatur zur weiteren Umsetzung mit (III) liegt ebenfalls im Bereich von -20\u00b0C bis +120\u00b0C, bevorzugt 0\u00b0C bis +100\u00b0C, besonders bevorzugt +25\u00b0C bis +80\u00b0C.", "Die Menge von (III) betr\u00e4gt 1 bis 20 Mol pro Mol (II). In Mengen au\u00dferhalb dieses Bereiches gilt das oben zur Menge an Mg bzw. Zn Gesagte. In bevorzugter Weise werden 1 bis 10 Mol (III), in besonders bevorzugter Weise 1 bis 2 Mol (III) pro Mol (II) eingesetzt.", "Nicht umgesetztes Mg bzw. Zn und (III) werden auf fachm\u00e4nnisch bekannte Weise vom Reaktionsansatz abgetrennt und k\u00f6nnen erneut eingesetzt werden.", "Das erfindungsgem\u00e4\u00dfe Verfahren kann in Gegenwart eines polaren, aprotischen L\u00f6sungsmittels durchgef\u00fchrt werden. Geeignete L\u00f6sungsmittels sind beispielsweise Methylenchlorid, Chloroform, Dimethylformamid, N-Methyl-pyrrolidon und Ether. Hiervon sind die Ether bevorzugt, beispielsweise Diethylether, Diisopropylether, Dioxan, Tetrahydrofuran und andere dem Fachmann bekannte. Die Menge L\u00f6sungsmittel wird so gew\u00e4hlt, dass (II) und die daraus entstehende Mg-organische bzw. Znorganische Verbindung gel\u00f6st vorliegen und das nicht umgesetzte Mg bzw. Zn etwa durch Filtration oder Dekantieren oder analoge Trennoperation abgetrennt werden kann. Diese Menge betr\u00e4gt beispielsweise 50 bis 1000 % der Menge von (II).", "Y ist in bevorzugter Weise -C(R", "F\u00fcr den Fall, dass Y die Bedeutung -Si(R", "F\u00fcr den Fall, dass die Umsetzung von (IV) mit (Va) oder (Vb) zu (VII) in Gegenwart einer Hilfsbase durchgef\u00fchrt wird, kommen hierf\u00fcr beispielsweise in Betracht: Offenkettige oder cyclische terti\u00e4re aliphatische Amine mit insgesamt 3 bis 30 C-Atomen, wie Trimethylamin, Triethylamin, Tripropylamin, Triisopropylamin, Tributylamin, Triisobutylamin, Trihexylamin, Trioctylamin, Tridecylamin, N-Methylpiperidin, N,N'-Dimethyl-piperazin, Diaza-bicyclo-nonan (DBN), Diazabicycloundecan (DBU), auch Amine mit unterschiedlich langen C-Ketten, wie N,N-Dimethyl-butylamin, N,N-Dimethyl-octylamin, N,N-Dimethyl-stearylamin und \u00e4hnliche, und aromatische Amine, wie Pyridin, Methylpyridine, Chinolin, N,N-Dimethyl-anilin und \u00e4hnliche.", "Die Aufarbeitung des die metallorganische Verbindung (I) enthaltenden Reaktionsgemisches erfolgt mit fachm\u00e4nnisch bekannten Operationen, wie Filtration, Abdestillieren fl\u00fcchtiger Gemischanteile und Kristallisation.", "Die Erfindung betrifft weiterhin die Verwendung der Verbindungen gem\u00e4\u00df Formel (I) als Katalysatoren sowohl auf einem Katalysatortr\u00e4ger (z.B. Al", "Die metallorganischen Verbindungen der Formel (I) k\u00f6nnen als Katalysatoren zur (Co)Polymerisation von C", "Verbindungen der Formel (I), in denen Y = -Si(R", "Die Verbindungen der Formel (I) werden zur (Co)Polymerisation h\u00e4ufig in Kombination mit Cokatalysatoren eingesetzt.", "Als Cokatalysatoren kommen die auf dem Gebiet der Metallocene bekannten Cokatalysatoren in Frage, wie polymere oder oligomere Alumoxane, Lewiss\u00e4uren sowie Aluminate und Borate. In diesem Zusammenhang wird insbesondere verwiesen auf Macromol. Symp. Vol. 97, Juli 1995, S. 1 - 246 (f\u00fcr Alumoxane), sowie auf EP-A1-277 003, EP-A1-277 004, Organometallics 1997,", "Insbesondere eignen sich als Cokatalysatoren Methylalumoxan, durch Triisobutylaluminium (TIBA) modifiziertes Methylalumoxan, sowie Diisobutylalumoxan, Trialkylaluminiumverbindungen, wie Trimethylaluminium, Triethylaluminium, Triisobutylaluminium, Triisooctylaluminium, dar\u00fcber hinaus Dialkylaluminium-Verbindungen wie Diisobutylaluminiumhydrid, Diethylaluminiumchlorid, substituierte Triarylborverbindungen, wie Tris(pentafluorphenyl)boran, sowie ionische Verbindungen, die als Anion Tetrakis(pentafluorphenyl)borat enthalten, wie Triphenylmethyltetrakis(pentafluorphenyl)borat, Trimethylammoniumtetrakis-(pentafluorphenyl)-borat, N,N-Dimethylaniliniumtetrakis(pentafluorphenyl)borat, substituierte Triarylaluminiumverbindungen, wie Tris(pentafluorphenyl)aluminium, sowie ionische Verbindungen, die als Anion Tetrakis(pentafluor-phenyl)aluminat enthalten, wie Triphenylmethyltetrakis(pentafluorphenyl)aluminat, N,N-Dimethylaniliniumtetrakis-(pentafluorphenyl)aluminat.", "Selbstverst\u00e4ndlich ist es m\u00f6glich, die Cokatalysatoren im Gemisch untereinander einzusetzen. Die jeweils g\u00fcnstigsten Mischungsverh\u00e4ltnisse sind durch geeignete Vorversuche zu bestimmen.", "Solche (Co)Polymerisationen werden in der Gas-, Fl\u00fcssig- oder Slurryphase ausgef\u00fchrt. Der Temperaturbereich hierzu reicht von -20\u00b0C bis +200\u00b0C, bevorzugt 0\u00b0C bis 160\u00b0C, besonders bevorzugt +20\u00b0C bis +80\u00b0C; der Druckbereich reicht von 1 bis 50 bar, bevorzugt 3 bis 30 bar. Mitverwendete L\u00f6sungsmittel sind beispielsweise: ges\u00e4ttigte Aliphaten oder (Halogen)Aromaten, wie Pentan, Hexan, Heptan, Cyclohexan, Petrolether, Petroleum, hydrierte Benzine, Benzol, Toluol, Xylol, Ethylbenzol, Chlorbenzol und analoge. Diese Reaktionsbedingungen zur (Co)Polymerisation sind dem Fachmann grunds\u00e4tzlich bekannt.", "Wichtige Polymere, die mit den erfindungsgem\u00e4\u00dfen metallorganischen Verbindungen als Katalysatoren hergestellt werden k\u00f6nnen, sind solche des Ethylens und Copolymere hiervon. Als Comonomere geeignet sind C", "Die so herstellbaren Ethylen(co)polymere besitzen Molekulargewichte mit M", "In der beschriebenen Weise lassen sich insbesondere auch Kautschuke auf Basis von Ethylen und einem oder mehreren der genannten Comonomere herstellen. Besonders bevorzugt ist die Copolymerisation von Ethylen und Propylen, wobei amorphe Ethylen(co)polymere mit einem Ethylenanteil im Polymeren im Bereich von 30 bis 70 Gew.-%, bevorzugt von 40 bis 65 Gew.-%, erhalten werden.", "In der beschriebenen Weise lassen sich auch EPDM-Kautschuke auf Basis von Ethylen, Propylen und einem Dien, vorzugsweise 5-Ethyliden-2-norbomen herstellen. Die EPDM-Kautschuke sind dadurch charakterisiert, dass sie hohe Molekulargewichte und geringe kristalline Anteile aufweisen.", "Mit den erfindungsgem\u00e4\u00dfen metallorganischen Verbindungen lassen sich besonders gut hochmolekulare ataktische Polymere, z. B. ataktisches Polypropylen herstellen.", "Beispielsweise kann die (Co)polymerisation von Ethylen mit oder ohne den genannten Comonomeren wie folgt durchgef\u00fchrt werden: ein Stahlautoklav wird nach den \u00fcblichen Reinigungsoperationen mit einem L\u00f6sungsmittel und einem Scavenger, z.B. Triisobutylaluminium bef\u00fcllt. Durch den Scavenger werden m\u00f6gliche Verunreinigungen und Katalysatorgifte, z.B. Wasser oder andere sauerstoffhaltigen Verbindungen unsch\u00e4dlich gemacht. Dann wird als Katalysatorvorstufe eine Verbindung der Formel (I) zugegeben. Anschlie\u00dfend wird der Reaktor mit Monomeren bis zu einem bestimmten Druck bef\u00fcllt, auf eine ausgew\u00e4hlte Temperatur thermostatisiert und die Polymerisation durch Zugabe eines oder mehrerer der zuvor genannten Cokatalysatoren gestartet. Die Polymerisation kann in einem kontinuierlichen oder diskontinuierlichen Proze\u00df erfolgen.", "Die Erfindung wird anhand der nachstehenden Beispiele n\u00e4her erl\u00e4utert.", "Allgemeine Angaben: Herstellung und Handhabung organometallischer Verbindungen erfolgten unter Ausschlu\u00df von Luft und Feuchtigkeit unter Argon-Schutz (Schlenk-Technik). Alle ben\u00f6tigten L\u00f6sungsmittel wurden vor Gebrauch durch mehrst\u00fcndiges Sieden \u00fcber einem geeigneten Trockenmittel und anschlie\u00dfende Destillation unter Argon absolutiert. Die Verbindungen wurden mit", "Die intrinsische Viskosit\u00e4t wurde in einem Ubbelohde-Kapillarviskosimeter bei 140\u00b0C in o-Dichlorbenzol als L\u00f6sungsmittel bestimmt (Mehrpunktmessung). Die DSC-Messungen erfolgten an einem Ger\u00e4t der Firma Perkin-Elmer mit der Bezeichnung Differential-Scanning-Calorimeter DSC-2 nach folgender Vorschrift: zwei Aufheizungen -90\u00b0C, bis +180\u00b0C, Heizrate 20K/min, schnelle Abk\u00fchlung mit 320K/min auf -90\u00b0C, Stickstoffsp\u00fclung, Einwaagen 12,3 mg Probenmasse in Normkapseln. Die NMR-Messungen zur Bestimmung der Mikrostruktur erfolgten in Tetrachlorethan an einem Ger\u00e4t der Firma Bruker DRX-400. Die Bestimmung der Mooneyviskosit\u00e4t erfolgte nach ASTM 1646 / DIN 53 523 bei einer Temperatur von 125\u00b0C. Die IR-spektroskopische Ermittlung der Polymerzusammensetzung erfolgte gem\u00e4\u00df ASTM D 3900.", "3-Phenylbutters\u00e4ure (26.1 g, 0.159 mol) wird bei 25\u00b0C in einer Portion mit Thionylchlorid (28.4 g, 17.3 mL, 0.24 mol) zur Reaktion gebracht. Es wird 4 h zum R\u00fcckflu\u00df erhitzt und 15 h bei 25\u00b0C ger\u00fchrt. Das \u00fcbersch\u00fcssige Thionylchlorid wird von der Reaktionsmischung destilliert (Sdp.: 79\u00b0C). Das erhaltene orangebraune \u00d6l wird in 100 mL Benzol gel\u00f6st, und auf 0\u00b0C gek\u00fchlt. Dazu gibt man portionsweise AlCl", "Ausb.: 21.0 g (0.144 mol, 90 % d. Th. bez. auf 3-Phenylbutters\u00e4ure).", "3,3-Diphenylpropions\u00e4ure (26.0 g, 0.11 mol) wird mit Thionylchlorid (19.6 g, 12 mL, 0.17 mol) versetzt, 4 h zum R\u00fcckflu\u00df erhitzt und 15 h bei 25\u00b0C ger\u00fchrt. Nun destilliert man das \u00fcbersch\u00fcssige Thionylchlorid ab (Sdp.: 79\u00b0C). Es verbleibt ein orangebraunes \u00d6l, welches in 100 mL Benzol gel\u00f6st wird. Die erhaltene L\u00f6sung wird auf 0\u00b0C gek\u00fchlt und portionsweise mit AlCl", "Dazu wurde das in Beispiel 1 hergestellte 3-Methylindan-1-on (21.0 g, 0.144 mol) wird in 20 mL Diethylether gel\u00f6st und zu einer L\u00f6sung von Methylmagnesiumjodid in Diethylether (Die Grignardl\u00f6sung wird durch Zutropfen von Methyljodid (25.4 g, 11.3 mL, 0.18 mol) in eine Suspension von Magnesiumpulver (4.4 g , 0.18 mol) in 40 mL Diethylether hergestellt.) getropft. Nach 2 h unter R\u00fcckflu\u00df wird auf 100 mL Eiswasser gegossen. Man s\u00e4uert mit 5 N Salzs\u00e4ure an, bis sich die ausgefallenen Magnesiumsalze gel\u00f6st haben. Von der organische Phase wird abgetrennt und die w\u00e4sserige Phase zweimal mit je 50 mL Diethylether extrahiert. Die vereinigten organischen Phasen werden mit je 30 mL einer ges\u00e4ttigten NaHCO", "3-Phenylindan-1-on aus Beispiel 2 (21.0 g, 0.144 mol) wird in 20 mL Diethylether gel\u00f6st und zu einer L\u00f6sung von Phenylmagnesiumbromid in Diethylether (Die Grignardl\u00f6sung wird durch Zutropfen von Phenylbromid (11.9 g, 8.8 mL, 0.0758 mol), gel\u00f6st in 25 mL Diethylether, zu Magnesiumpulver (2.02 g, 0.0758 mol) in 25 mL Diethylether hergestellt.) getropft. Nun wird 1.5 h zum R\u00fcckflu\u00df erhitzt, weitere 15 h bei 25\u00b0C ger\u00fchrt und danach auf 100 mL Eiswasser gegossen. Man s\u00e4uert mit 5 N Salzs\u00e4ure an bis sich die gebildeten Magnesiumsalze gel\u00f6st haben. Die organische Phase wird separiert und die w\u00e4sserige Phase zweimal mit je 50 mL Diethylether extrahiert. Die vereinigten organischen Phasen werden mit je 30 mL ges\u00e4ttigter NaHCO", "1,3-Dimethylinden aus Beispiel 3 (4.9 g, 0.0343 mol) wird bei 25\u00b0C in 150 mL Diethylether gel\u00f6st. Bei 0\u00b0C wird Brom (5.5 g, 1.76 mL, 0.0345 mol) tropfenweise zugegeben. Nach 3 h R\u00fchren bei 25\u00b0C werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Es wird ein braunes \u00d6l erhalten. Die Reinigung erfolgt durch eine S\u00e4ulenchromatographie mit Kieselgel als station\u00e4re Phase und eine Mischung aus Hexan und Methylenchlorid (10:1) als mobile Phase (S\u00e4ulendurchmesser: 3.0 cm, F\u00fcllh\u00f6he: 20 cm). Man erh\u00e4lt ein hellgelbes \u00d6l.", "Das in Beispiel 4 dargestellte 1,3-Diphenylinden (5.0 g, 0.0186 mol) wird bei 25\u00b0C in 150 mL Diethylether gel\u00f6st. Bei 0\u00b0C wird Brom (2.98 g, 0.96 mL, 0.0186 mol) tropfenweise zugegeben. Nach 3 h R\u00fchren bei 25\u00b0C werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Es wird ein viskoses, braunes \u00d6l erhalten. Die Reinigung erfolgt durch eine S\u00e4ulenchromatographie mit Kieselgel als station\u00e4re Phase und einer Mischung aus Hexan und Methylenchlorid (10:1) als mobile Phase (S\u00e4ulendurchmesser: 3.0 cm, F\u00fcllh\u00f6he: 20 cm). Man erh\u00e4lt einen farblosen Feststoff.", "F\u00fcr die R\u00f6ntgenstrukturanalyse konnten geeignete Einkristalle durch Kristallisation bei 25\u00b0C aus Petrolether erhalten werden.", "Dazu wurde das in Beispiel 5 erhaltene 2-Brom-1,3-dimethylinden (2.5 g, 0.0112 mol) in 5 mL Tetrahydrofuran gel\u00f6st und zu einer Mischung aus Magnesiumpulver (0.5 g, 0.02 mol) und Dichlordimethylsilan (3.9 g, 3.6 mL, 0.03 mol) in 15 mL Tetrahydrofuran getropft. Dabei siedet die L\u00f6sung (Anm.: Ist keine spontane Erw\u00e4rmung der Reaktionsl\u00f6sung zu bemerken, so l\u00e4\u00dft sich diese durch Zugabe weniger Tropfen 1,2-Dibromethan ausl\u00f6sen). Man l\u00e4\u00dft 15 h bei 25\u00b0C r\u00fchren und entfernt danach alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum. Nun werden 40 mL Petrolether zugegeben und die erhaltene Suspension zur Entfernung des Magnesiumsalzes filtriert. Vom erhaltenen Filtrat werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Man l\u00f6st das erhaltene hellgelbe \u00d6l in 30 mL Diethylether und k\u00fchlt auf 0\u00b0C. Nun gibt man \u00fcber NaH getrocknetes", "2-Brom-1,3-diphenylinden (Beispiel 6) (2.5 g, 0.0072 mol) wird in 5 mL Tetrahydrofuran gel\u00f6st und zu einer Mischung aus Magnesiumpulver (0.35 g, 0.0144 mol) und Dichlordimethylsilan (2.8 g, 2.6 mL, 0.0216 mol) in 10 mL Tetrahydrofuran getropft. Dabei siedet die L\u00f6sung. Man l\u00e4\u00dft 15 h bei 25\u00b0C r\u00fchren und entfernt danach alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum. Nun werden 40 mL Petrolether addiert und das Magnesiumsalz durch Filtration durch eine G3-Fritte abgetrennt. Vom erhaltenen Filtrat werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Man l\u00f6st das erhaltene hellgelbe \u00d6l in 30 mL Diethylether und k\u00fchlt auf 0\u00b0C. Nun wird \u00fcber NaH getrocknetes", "Das in Beispiel 5 erhaltene 2-Brom-1,3-dimethylinden (2.5 g, 0.0112 mol) wird in 5 mL Tetrahydrofuran gel\u00f6st und zu einer Mischung bestehend aus Magnesiumpulver (0.5 g, 0.02 mol) und Dichlordimethylsilan (3.9 g, 3.6 mL, 0.03 mol) in 15 mL Tetrahydrofuran getropft. Dabei siedet die L\u00f6sung. Man l\u00e4\u00dft 15 h bei 25\u00b0C r\u00fchren und entfernt danach alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum. Nun werden 40 mL Petrolether zugegeben und das Magnesiumsalz durch Filtration durch eine G3-Fritte abgetrennt. Vom erhaltenen Filtrat werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Man l\u00f6st das erhaltene hellgelbe \u00d6l in 30 mL Diethylether und k\u00fchlt auf 0\u00b0C. Nun wird Cyclopentadienylnatrium (1.0 g, 0.0112 mol) gel\u00f6st in 10 mL Tetrahydrofuran addiert. Es wird 15 h bei 25\u00b0C ger\u00fchrt und anschlie\u00dfend alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Danach werden 35 mL Petrolether zugegeben und von ausgefallenem NaCl durch Kieselgur (G4-Fritte) filtriert. Die Reinigung des R\u00fcckstandes erfolgt \u00fcber eine S\u00e4ulenchromatographie mit Kieselgel als station\u00e4re Phase und eine Mischung aus Hexan und Methylenchlorid (10:1) als mobile Phase (S\u00e4ulendurchmesser: 3.0 cm, F\u00fcllh\u00f6he: 20 cm). Es wird ein hellgelbes \u00d6l erhalten.", "2-Brom-1,3-diphenylinden (2.5 g, 0.0072 mol) aus Beispiel 6 wird in 5 mL Tetrahydrofuran gel\u00f6st und zu einer Mischung bestehend aus Magnesiumpulver (0.35 g, 0.0144 mol) und Dichlordimethylsilan (2.8 g, 2.6 mL, 0.0216 mol) in 10 mL Tetrahydrofuran getropft. Dabei siedet die L\u00f6sung. Man l\u00e4\u00dft 15 h bei 25\u00b0C r\u00fchren und entfernt danach alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum. Es werden 40 mL Petrolether zugegeben und die erhaltene Suspension zur Entfernung des Magnesiumsalzes durch eine G4 Fritte filtriert. Vom erhaltenen Filtrat werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Man l\u00f6st das erhaltene hellgelbe \u00d6l in 20 mL Diethylether und k\u00fchlt auf 0\u00b0C. Nun wird Cyclopentadienylnatrium (0.634 g, 0.0072 mol), gel\u00f6st in 5 mL Tetrahydrofuran, zugegeben. Es wird 15 h bei 25\u00b0C ger\u00fchrt und anschlie\u00dfend alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt. Danach werden 35 mL Petrolether zugegeben und vom ausgefallenen Natriumchlorid filtriert. Die Reinigung des R\u00fcckstandes erfolgt durch eine S\u00e4ulenchromatographie mit Kieselgel als station\u00e4re Phase und eine Mischung aus Hexan und Methylenchlorid (10:1) als mobile Phase (S\u00e4ulendurchmesser: 3.0 cm, F\u00fcllh\u00f6he: 20 cm). Es wird ein hellgelbes, viskoses \u00d6l erhalten.", "Das in Beispiel 7 hergestellte 2-(", "TiCl", "Dazu wurde das in Beispiel 8 hergestellte 2-(", "Anschlie\u00dfend l\u00f6st man das Dilithiumsalz Li", "Ausb.: 0.6 g (1.07 mmol, 61 % d. Th. bez. auf 2-(", "2-(Cyclopentadienyldimethylsilyl)-1,3-dimethylinden (0.53 g, 1.99 mmol) aus Beispiel 9 wird in 10 mL Diethylether gel\u00f6st und bei -78\u00b0C mit einer 2.5 N L\u00f6sung von n-BuLi in Hexan (1.6 mL, 3.98 mol) metalliert. Nach Erw\u00e4rmen auf 25\u00b0C wird weitere 4 h ger\u00fchrt. Danach werden alle fl\u00fcchtige Bestandteile im \u00d6lpumpenvakuum entfernt, der R\u00fcckstand zweimal mit je 15 mL Petrolether gewaschen und das Dilithiumsalz in 15 mL Toluol suspendiert. Nun wird auf -20\u00b0C gek\u00fchlt. Man gibt Zircontetrachlorid (0.465 g, 2.00 mmol), suspendiert in 10 mL Toluol, zu und r\u00fchrt 15 h bei 25\u00b0C. Nun werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt, der R\u00fcckstand mit 5 mL Petrolether gewaschen und im \u00d6lpumpenvakuum der Petrolether entfernt. Nun gibt man 30 mL Methylenchlorid zu und filtiert die L\u00f6sung zur Entfernung aller unl\u00f6slichen Bestandteile durch Kieselgur durch eine G4-Fritte. Nach Entfernung des Methylenchlorids im \u00d6lpumpenvakuum erh\u00e4lt man einen zitronengelben Feststoff.", "Das in Beispiel 10 hergestellte 2-(Cyclopentadienyldimethylsilyl)-1,3-diphenylinden (0.81 g, 2.077 mmol) wird in 25 mL Diethylether gel\u00f6st und bei -78\u00b0C mit einer 2.5 N L\u00f6sung von n-BuLi in Hexan (1.7 mL, 4.15 mol) metalliert. Nach Erw\u00e4rmen auf 25\u00b0C wird weitere 4 h ger\u00fchrt. Danach werden alle fl\u00fcchtige Bestandteile im \u00d6lpumpenvakuum entfernt, der R\u00fcckstand zweimal mit je 15 mL Petrolether gewaschen und in 20 mL Toluol suspendiert. Nun wird auf -20\u00b0C gek\u00fchlt. Man gibt Zirconiumtetrachlorid (0.48 g, 2.06 mmol), suspendiert in 15 mL Toluol, zu und r\u00fchrt 15 h bei 25\u00b0C. Es werden alle fl\u00fcchtigen Bestandteile im \u00d6lpumpenvakuum entfernt, der R\u00fcckstand mit 10 mL Petrolether gewaschen und anschlie\u00dfend im \u00d6lpumpenvakuum getrocknet. Nun gibt man 30 mL Methylenchlorid zu und filtiert die L\u00f6sung zur Entfernung aller unl\u00f6slichen Bestandteile durch Kieselgur (G4-Fritte). Nach Entfernung des Methylenchlorids im \u00d6lpumpenvakuum erh\u00e4lt man einen kanariengelben Feststoff. F\u00fcr die R\u00f6ntgenstrukturanalyse (Fig. 1) konnten geeignete Einkristalle durch Kristallisation bei -20\u00b0C aus Methylenchlorid erhalten werden.", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 2,0 mg (5 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 2,0 mg (5 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 5.4 mg (15 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 5.4 mg (15 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 2.0 mg (10 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Hexan und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 1,8 mg (5 \u00b5mol) 2-(", "In einen 1,4-1-Stahl-Autoklaven, der mit einem mechanischen R\u00fchrer, Manometer, Temperaturf\u00fchler, einer Temperatursteuervorrichtung, einer Katalysatorschleuse und Monomerdosiervorrichtungen f\u00fcr Ethylen und Propylen ausgestattet ist, wurden 500 ml Toluol und 1 ml TIBA vorgelegt. Hierzu wurde eine L\u00f6sung von 1,4 mg (2,5 \u00b5mol) 2-(Cyclopentadienyldimethylsilyl)-1,3-diphenylindenzirconocendichlorid aus Beispiel 14 in 1,25 ml Toluol gegeben. Die Innentemperatur wurde mit einem Thermostaten auf 40\u00b0C eingestellt. Anschlie\u00dfend wurden 30,5 g Propylen (2,8 bar) und 13,5 g Ethylen (Gesamtdruck bis 7 bar) zudosiert. Durch Zugabe einer L\u00f6sung von 4.6 mg (5 \u00b5mol) Triphenylmethyl-tetrakis(pentafluorphenyl)borat in 2,5 ml Toluol wurde die Polymerisation gestartet. W\u00e4hrend der Polymerisation stieg die Innentemperatur auf 53\u00b0C an. Nach 12 Minuten Polymerisationsdauer wurde der Autoklav entspannt. Zur Aufarbeitung wurde das Polymer in Methanol ausgef\u00e4llt und 20 h bei 60\u00b0C im Vakuum getrocknet, wobei 32,9 g Copolymer erhalten wurden. Es wurde ein gummiartiges Polymer erhalten. Die IR-spektroskopische Ermittlung der Zusammensetzung des Copolymeren ergab einen Einbau von 72,0 Gew.-% Ethylen und 28,0 Gew.-% Propylen. Mit der DSC-Methode wurde ein Tg von -46\u00b0C ermittelt. Die Messung der intrinsischen Viskosit\u00e4t ergab einen Wert von I.V. = 1,8 dl/g."], "tags": ["C08F", "C07F"]}, {"docid": "EP1536414A2", "paras": ["The present invention relates to noise reduction. In particular, the present invention relates to removing noise from speech signals.", "A common problem in speech recognition and speech transmission is the corruption of the speech signal by additive noise. In particular, corruption due to the speech of another speaker has proven to be difficult to detect and/or correct.", "One technique for removing noise attempts to model the noise using a set of noisy training signals collected under various conditions. These training signals are received before a test signal that is to be decoded or transmitted and are used for training purposes only. Although such systems attempt to build models that take noise into consideration, they are only effective if the noise conditions of the training signals match the noise conditions of the test signals. Because of the large number of possible noises and the seemingly infinite combinations of noises, it is very difficult to build noise models from training signals that can handle every test condition.", "Another technique for removing noise is to estimate the noise in the test signal and then subtract it from the noisy speech signal. Typically, such systems estimate the noise from previous frames of the test signal. As such, if the noise is changing over time, the estimate of the noise for the current frame will be inaccurate.", "One system of the prior art for estimating the noise in a speech signal uses the harmonics of human speech. The harmonics of human speech produce peaks in the frequency spectrum. By identifying nulls between these peaks, these systems identify the spectrum of the noise. This spectrum is then subtracted from the spectrum of the noisy speech signal to provide a clean speech signal.", "The harmonics of speech have also been used in speech coding to reduce the amount of data that must be sent when encoding speech for transmission across a digital communication path. Such systems attempt to separate the speech signal into a harmonic component and a random component. Each component is then encoded separately for transmission. One system in particular used a harmonic+noise model in which a sum-of-sinusoids model is fit to the speech signal to perform the decomposition.", "In speech coding, the decomposition is done to find a parameterization of the speech signal that accurately represents the input noisy speech signal. The decomposition has no noise-reduction capability.", "Recently, a system has been developed that attempts to remove noise by using a combination of an alternative sensor, such as a bone conduction microphone, and an air conduction microphone. This system is trained using three training channels: a noisy alternative sensor training signal, a noisy air conduction microphone training signal, and a clean air conduction microphone training signal. Each of the signals is converted into a feature domain. The features for the noisy alternative sensor signal and the noisy air conduction microphone signal are combined into a single vector representing a noisy signal. The features for the clean air conduction microphone signal form a single clean vector. These vectors are then used to train a mapping between the noisy vectors and the clean vectors. Once trained, the mappings are applied to a noisy vector formed from a combination of a noisy alternative sensor test signal and a noisy air conduction microphone test signal. This mapping produces a clean signal vector.", "This system is less than optimum when the noise conditions of the test signals do not match the noise conditions of the training signals because the mappings are designed for the noise conditions of the training signals.", "A method and system use an alternative sensor signal received from a sensor other than an air conduction microphone to estimate a clean speech value. The clean speech value is estimated without using a model trained from noisy training data collected from an air conduction microphone. Under one embodiment, correction vectors are added to a vector formed from the alternative sensor signal in order to form a filter, which is applied to the air conductive microphone signal to produce the clean speech estimate. In other embodiments, the pitch of a speech signal is determined from the alternative sensor signal and is used to decompose an air conduction microphone signal. The decomposed signal is then used to identify a clean signal estimate.", "FIG. 1 illustrates an example of a suitable computing system environment 100 on which the invention may be implemented. The computing system environment 100 is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment 100 be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment 100.", "The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well-known computing systems, environments, and/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, telephony systems, distributed computing environments that include any of the above systems or devices, and the like.", "The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention is designed to be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules are located in both local and remote computer storage media including memory storage devices.", "With reference to FIG. 1, an exemplary system for implementing the invention includes a general-purpose computing device in the form of a computer 110. Components of computer 110 may include, but are not limited to, a processing unit 120, a system memory 130, and a system bus 121 that couples various system components including the system memory to the processing unit 120. The system bus 121 may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.", "Computer 110 typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer 110 and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer 110. Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \"modulated data signal\" means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.", "The system memory 130 includes computer storage media in the form of volatile and/or nonvolatile memory such as read only memory (ROM) 131 and random access memory (RAM) 132. A basic input/output system 133 (BIOS), containing the basic routines that help to transfer information between elements within computer 110, such as during start-up, is typically stored in ROM 131. RAM 132 typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by processing unit 120. By way of example, and not limitation, FIG. 1 illustrates operating system 134, application programs 135, other program modules 136, and program data 137.", "The computer 110 may also include other removable/non-removable volatile/nonvolatile computer storage media. By way of example only, FIG. 1 illustrates a hard disk drive 141 that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive 151 that reads from or writes to a removable, nonvolatile magnetic disk 152, and an optical disk drive 155 that reads from or writes to a removable, nonvolatile optical disk 156 such as a CD ROM or other optical media. Other removable/non-removable, volatile/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive 141 is typically connected to the system bus 121 through a non-removable memory interface such as interface 140, and magnetic disk drive 151 and optical disk drive 155 are typically connected to the system bus 121 by a removable memory interface, such as interface 150.", "The drives and their associated computer storage media discussed above and illustrated in FIG. 1, provide storage of computer readable instructions, data structures, program modules and other data for the computer 110. In FIG. 1, for example, hard disk drive 141 is illustrated as storing operating system 144, application programs 145, other program modules 146, and program data 147. Note that these components can either be the same as or different from operating system 134, application programs 135, other program modules 136, and program data 137. Operating system 144, application programs 145, other program modules 146, and program data 147 are given different numbers here to illustrate that, at a minimum, they are different copies.", "A user may enter commands and information into the computer 110 through input devices such as a keyboard 162, a microphone 163, and a pointing device 161, such as a mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit 120 through a user input interface 160 that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor 191 or other type of display device is also connected to the system bus 121 via an interface, such as a video interface 190. In addition to the monitor, computers may also include other peripheral output devices such as speakers 197 and printer 196, which may be connected through an output peripheral interface 195.", "The computer 110 is operated in a networked environment using logical connections to one or more remote computers, such as a remote computer 180. The remote computer 180 may be a personal computer, a hand-held device, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer 110. The logical connections depicted in FIG. 1 include a local area network (LAN) 171 and a wide area network (WAN) 173, but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.", "When used in a LAN networking environment, the computer 110 is connected to the LAN 171 through a network interface or adapter 170. When used in a WAN networking environment, the computer 110 typically includes a modem 172 or other means for establishing communications over the WAN 173, such as the Internet. The modem 172, which may be internal or external, may be connected to the system bus 121 via the user input interface 160, or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer 110, or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation, FIG. 1 illustrates remote application programs 185 as residing on remote computer 180. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.", "FIG. 2 is a block diagram of a mobile device 200, which is an exemplary computing environment. Mobile device 200 includes a microprocessor 202, memory 204, input/output (I/O) components 206, and a communication interface 208 for communicating with remote computers or other mobile devices. In one embodiment, the afore-mentioned components are coupled for communication with one another over a suitable bus 210.", "Memory 204 is implemented as non-volatile electronic memory such as random access memory (RAM) with a battery back-up module (not shown) such that information stored in memory 204 is not lost when the general power to mobile device 200 is shut down. A portion of memory 204 is preferably allocated as addressable memory for program execution, while another portion of memory 204 is preferably used for storage, such as to simulate storage on a disk drive.", "Memory 204 includes an operating system 212, application programs 214 as well as an object store 216. During operation, operating system 212 is preferably executed by processor 202 from memory 204. Operating system 212, in one preferred embodiment, is a WINDOWS\u00ae CE brand operating system commercially available from Microsoft Corporation. Operating system 212 is preferably designed for mobile devices, and implements database features that can be utilized by applications 214 through a set of exposed application programming interfaces and methods. The objects in object store 216 are maintained by applications 214 and operating system 212, at least partially in response to calls to the exposed application programming interfaces and methods.", "Communication interface 208 represents numerous devices and technologies that allow mobile device 200 to send and receive information. The devices include wired and wireless modems, satellite receivers and broadcast tuners to name a few. Mobile device 200 can also be directly connected to a computer to exchange data therewith. In such cases, communication interface 208 can be an infrared transceiver or a serial or parallel communication connection, all of which are capable of transmitting streaming information.", "Input/output components 206 include a variety of input devices such as a touch-sensitive screen, buttons, rollers, and a microphone as well as a variety of output devices including an audio generator, a vibrating device, and a display. The devices listed above are by way of example and need not all be present on mobile device 200. In addition, other input/output devices may be attached to or found with mobile device 200 within the scope of the present invention.", "FIG. 3 provides a basic block diagram of embodiments of the present invention. In FIG. 3, a speaker 300 generates a speech signal 302 that is detected by an air conduction microphone 304 and an alternative sensor 306. Examples of alternative sensors include a throat microphone that measures the user's throat vibrations, a bone conduction sensor that is located on or adjacent to a facial or skull bone of the user (such as the jaw bone) or in the ear of the user and that senses vibrations of the skull and jaw that correspond to speech generated by the user. Air conduction microphone 304 is the type of microphone that is used commonly to convert audio air-waves into electrical signals.", "Air conduction microphone 304 also receives noise 308 generated by one or more noise sources 310. Depending on the type of alternative sensor and the level of the noise, noise 308 may also be detected by alternative sensor 306. However, under embodiments of the present invention, alternative sensor 306 is typically less sensitive to ambient noise than air conduction microphone 304. Thus, the alternative sensor signal 312 generated by alternative sensor 306 generally includes less noise than air conduction microphone signal 314 generated by air conduction microphone 304.", "Alternative sensor signal 312 and air conduction microphone signal 314 are provided to a clean signal estimator 316, which estimates a clean signal 318. Clean signal estimate 318 is provided to a speech process 320. Clean signal estimate 318 may either be a filtered time-domain signal or a feature domain vector. If clean signal estimate 318 is a time-domain signal, speech process 320 may take the form of a listener, a speech coding system, or a speech recognition system. If clean signal estimate 318 is a feature domain vector, speech process 320 will typically be a speech recognition system.", "The present invention provides several methods and systems for estimating clean speech using air conduction microphone signal 314 and alternative sensor signal 312. One system uses stereo training data to train correction vectors for the alternative sensor signal. When these correction vectors are later added to a test alternative sensor vector, they provide an estimate of a clean signal vector. One further extension of this system is to first track time-varying distortion and then to incorporate this information into the computation of the correction vectors and into the estimation of clean speech.", "A second system provides an interpolation between the clean signal estimate generated by the correction vectors and an estimate formed by subtracting an estimate of the current noise in the air conduction test signal from the air conduction signal. A third system uses the alternative sensor signal to estimate the pitch of the speech signal and then uses the estimated pitch to identify an estimate for the clean signal. Each of these systems is discussed separately below.", "FIGS. 4 and 5 provide a block diagram and flow diagram for training stereo correction vectors for the two embodiments of the present invention that rely on correction vectors to generate an estimate of clean speech.", "The method of identifying correction vectors begins in step 500 of FIG. 5, where a \"clean\" air conduction microphone signal is converted into a sequence of feature vectors. To do this, a speaker 400 of FIG. 4, speaks into an air conduction microphone 410, which converts the audio waves into electrical signals. The electrical signals are then sampled by an analog-to-digital converter 414 to generate a sequence of digital values, which are grouped into frames of values by a frame constructor 416. In one embodiment, A-to-D converter 414 samples the analog signal at 16 kHz and 16 bits per sample, thereby creating 32 kilobytes of speech data per second and frame constructor 416 creates a new frame every 10 milliseconds that includes 25 milliseconds worth of data.", "Each frame of data provided by frame constructor 416 is converted into a feature vector by a feature extractor 418. Under one embodiment, feature extractor 418 forms cepstral features. Examples of such features include LPC derived cepstrum, and Mel-Frequency Cepstrum Coefficients. Examples of other possible feature extraction modules that may be used with the present invention include modules for performing Linear Predictive Coding (LPC), Perceptive Linear Prediction (PLP), and Auditory model feature extraction. Note that the invention is not limited to these feature extraction modules and that other modules may be used within the context of the present invention.", "In step 502 of FIG. 5, an alternative sensor signal is converted into feature vectors. Although the conversion of step 502 is shown as occurring after the conversion of step 500, any part of the conversion may be performed before, during or after step 500 under the present invention. The conversion of step 502 is performed through a process similar to that described above for step 500.", "In the embodiment of FIG. 4, this process begins when alternative sensor 402 detects a physical event associated with the production of speech by speaker 400 such as bone vibration or facial movement. As shown in FIG. 11, in one embodiment of a bone conduction sensor 1100, a soft elastomer bridge 1102 is adhered to the diaphragm 1104 of a normal air conduction microphone 1106. This soft bridge 1102 conducts vibrations from skin contact 1108 of the user directly to the diaphragm 1104 of microphone 1106. The movement of diaphragm 1104 is converted into an electrical signal by a transducer 1110 in microphone 1106. Alternative sensor 402 converts the physical event into analog electrical signal, which is sampled by an analog-to-digital converter 404. The sampling characteristics for A/D converter 404 are the same as those described above for A/D converter 414. The samples provided by A/D converter 404 are collected into frames by a frame constructor 406, which acts in a manner similar to frame constructor 416. These frames of samples are then converted into feature vectors by a feature extractor 408, which uses the same feature extraction method as feature extractor 418.", "The feature vectors for the alternative sensor signal and the air conductive signal are provided to a noise reduction trainer 420 in FIG. 4. At step 504 of FIG. 5, noise reduction trainer 420 groups the feature vectors for the alternative sensor signal into mixture components. This grouping can be done by grouping similar feature vectors together using a maximum likelihood training technique or by grouping feature vectors that represent a temporal section of the speech signal together. Those skilled in the art will recognize that other techniques for grouping the feature vectors may be used and that the two techniques listed above are only provided as examples.", "Noise reduction trainer 420 then determines a correction vector, r", "Where", "The E- and M-steps of the algorithm iterate until stable values for the model parameters are determined. These parameters are then used to evaluate equation 1 to form the correction vectors. The correction vectors and the model parameters are then stored in a noise reduction parameter storage 422.", "After a correction vector has been determined for each mixture component at step 508, the process of training the noise reduction system of the present invention is complete. Once a correction vector has been determined for each mixture, the vectors may be used in a noise reduction technique of the present invention. Two separate noise reduction techniques that use the correction vectors are discussed below.", "A system and method that reduces noise in a noisy speech signal based on correction vectors and a noise estimate is shown in the block diagram of FIG. 6 and the flow diagram of FIG. 7, respectively.", "At step 700, an audio test signal detected by an air conduction microphone 604 is converted into feature vectors. The audio test signal received by microphone 604 includes speech from a speaker 600 and additive noise from one or more noise sources 602. The audio test signal detected by microphone 604 is converted into an electrical signal that is provided to analog-to-digital converter 606.", "A-to-D converter 606 converts the analog signal from microphone 604 into a series of digital values. In several embodiments, A-to-D converter 606 samples the analog signal at 16 kHz and 16 bits per sample, thereby creating 32 kilobytes of speech data per second. These digital values are provided to a frame constructor 607, which, in one embodiment, groups the values into 25 millisecond frames that start 10 milliseconds apart.", "The frames of data created by frame constructor 607 are provided to feature extractor 610, which extracts a feature from each frame. Under one embodiment, this feature extractor is different from feature extractors 408 and 418 that were used to train the correction vectors. In particular, under this embodiment, feature extractor 610 produces power spectrum values instead of cepstral values. The extracted features are provided to a clean signal estimator 622, a speech detection unit 626 and a noise model trainer 624.", "At step 702, a physical event, such as bone vibration or facial movement, associated with the production of speech by speaker 600 is converted into a feature vector. Although shown as a separate step in FIG. 7, those skilled in the art will recognize that portions of this step may be done at the same time as step 700. During step 702, the physical event is detected by alternative sensor 614. Alternative sensor 614 generates an analog electrical signal based on the physical events. This analog signal is converted into a digital signal by analog-to-digital converter 616 and the resulting digital samples are grouped into frames by frame constructor 617. Under one embodiment, analog-to-digital converter 616 and frame constructor 617 operate in a manner similar to analog-to-digital converter 606 and frame constructor 607.", "The frames of digital values are provided to a feature extractor 620, which uses the same feature extraction technique that was used to train the correction vectors. As mentioned above, examples of such feature extraction modules include modules for performing Linear Predictive Coding (LPC), LPC derived cepstrum, Perceptive Linear Prediction (PLP), Auditory model feature extraction, and Mel-Frequency Cepstrum Coefficients (MFCC) feature extraction. In many embodiments, however, feature extraction techniques that produce cepstral features are used.", "The feature extraction module produces a stream of feature vectors that are each associated with a separate frame of the speech signal. This stream of feature vectors is provided to clean signal estimator 622.", "The frames of values from frame constructor 617 are also provided to a feature extractor 621, which in one embodiment extracts the energy of each frame. The energy value for each frame is provided to a speech detection unit 626.", "At step 704, speech detection unit 626 uses the energy feature of the alternative sensor signal to determine when speech is likely present. This information is passed to noise model trainer 624, which attempts to model the noise during periods when there is no speech at step 706.", "Under one embodiment, speech detection unit 626 first searches the sequence of frame energy values to find a peak in the energy. It then searches for a valley after the peak. The energy of this valley is referred to as an energy separator,", "Under one embodiment, a fixed threshold value is used to determine if speech is present such that if the confidence value exceeds the threshold, the frame is considered to contain speech and if the confidence value does not exceed the threshold, the frame is considered to contain non-speech. Under one embodiment, a threshold value of 0.1 is used.", "For each non-speech frame detected by speech detection unit 626, noise model trainer 624 updates a noise model 625 at step 706. Under one embodiment, noise model 625 is a Gaussian model that has a mean \u00b5", "Correction vectors and model parameters in parameter storage 422 and noise model 625 are provided to clean signal estimator 622 with the feature vectors,", "At step 710, the initial alternative sensor clean speech estimate is refined by combining it with a clean speech estimate that is formed from the noisy air conduction microphone vector and the noise model. This results in a refined clean speech estimate 628. In order to combine the cepstral value of the initial clean signal estimate with the power spectrum feature vector of the noisy air conduction microphone, the cepstral value is converted to the power spectrum domain using:", "Once the initial clean signal estimate from the alternative sensor has been placed in the power spectrum domain, it can be combined with the noisy air conduction microphone vector and the noise model as:", "In a simplified embodiment, we rewrite EQ.10 as the following equation:", "The refined clean signal estimate in the power spectrum domain may be used to construct a Wiener filter to filter the noisy air conduction microphone signal. In particular, the Wiener filter, H, is set such that:", "This filter can then be applied against the time domain noisy air conduction microphone signal to produce a noise-reduced or clean time-domain signal. The noise-reduced signal can be provided to a listener or applied to a speech recognizer.", "Note that Equation 12 provides a refined clean signal estimate that is the weighted sum of two factors, one of which is a clean signal estimate from an alternative sensor. This weighted sum can be extended to include additional factors for additional alternative sensors. Thus, more than one alternate sensor may be used to generate independent estimates of the clean signal. These multiple estimates can then be combined using equation 12.", "FIG. 8 provides a block diagram of an alternative system for estimating a clean speech value under the present invention. The system of FIG. 8 is similar to the system of FIG. 6 except that the estimate of the clean speech value is formed without the need for an air conduction microphone or a noise model.", "In FIG. 8, a physical event associated with a speaker 800 producing speech is converted into a feature vector by alternative sensor 802, analog-to-digital converter 804, frame constructor 806 and feature extractor 808, in a manner similar to that discussed above for alternative sensor 614, analog-to-digital converter 616, frame constructor 617 and feature extractor 618 of FIG. 6. The feature vectors from feature extractor 808 and the noise reduction parameters 422 are provided to a clean signal estimator 810, which determines an estimate of a clean signal value 812,", "The clean signal estimate,", "This filter can then be applied against the time domain noisy air conduction microphone signal to produce a noise-reduced or clean signal. The noise-reduced signal can be provided to a listener or applied to a speech recognizer.", "Alternatively, the clean signal estimate in the cepstral domain,", "An alternative technique for generating estimates of a clean speech signal is shown in the block diagram of FIG. 9 and the flow diagram of FIG. 10. In particular, the embodiment of FIGS. 9 and 10 determine a clean speech estimate by identifying a pitch for the speech signal using an alternative sensor and then using the pitch to decompose a noisy air conduction microphone signal into a harmonic component and a random component. Thus, the noisy signal is represented as:", "Under one embodiment, the harmonic component is modeled as a sum of harmonically-related sinusoids such that:", "Thus, to identify the harmonic component, an estimate of the pitch frequency and the amplitude parameters {", "At step 1000, a noisy speech signal is collected and converted into digital samples. To do this, an air conduction microphone 904 converts audio waves from a speaker 900 and one or more additive noise sources 902 into electrical signals. The electrical signals are then sampled by an analog-to-digital converter 906 to generate a sequence of digital values. In one embodiment, A-to-D converter 906 samples the analog signal at 16 kHz and 16 bits per sample, thereby creating 32 kilobytes of speech data per second. At step 1002, the digital samples are grouped into frames by a frame constructor 908. Under one embodiment, frame constructor 908 creates a new frame every 10 milliseconds that includes 25 milliseconds worth of data.", "At step 1004, a physical event associated with the production of speech is detected by alternative sensor 944. In this embodiment, an alternative sensor that is able to detect harmonic components, such as a bone conduction sensor, is best suited to be used as alternative sensor 944. Note that although step 1004 is shown as being separate from step 1000, those skilled in the art will recognize that these steps may be performed at the same time. The analog signal generated by alternative sensor 944 is converted into digital samples by an analog-to-digital converter 946. The digital samples are then grouped into frames by a frame constructer 948 at step 1006.", "At step 1008, the frames of the alternative sensor signal are used by a pitch tracker 950 to identify the pitch or fundamental frequency of the speech.", "An estimate for the pitch frequency can be determined using any number of available pitch tracking systems. Under many of these systems, candidate pitches are used to identify possible spacing between the centers of segments of the alternative sensor signal. For each candidate pitch, a correlation is determined between successive segments of speech. In general, the candidate pitch that provides the best correlation will be the pitch frequency of the frame. In some systems, additional information is used to refine the pitch selection such as the energy of the signal and/or an expected pitch track.", "Given an estimate of the pitch from pitch tracker 950, the air conduction signal vector can be decomposed into a harmonic component and a random component at step 1010. To do so, equation 17 is rewritten as:", "Using", "An estimate of the random component is then calculated as:", "Thus, using equations 18-24 above, harmonic decompose unit 910 is able to produce a vector of harmonic component samples 912,", "After the samples of the frame have been decomposed into harmonic and random samples, a scaling parameter or weight is determined for the harmonic component at step 1012. This scaling parameter is used as part of a calculation of a noise-reduced speech signal as discussed further below. Under one embodiment, the scaling parameter is calculated as:", "In alternative embodiments, the scaling parameter is set using a probabilistic voiced-unvoiced detection unit. Such units provide the probability that a particular frame of speech is voiced, meaning that the vocal cords resonate during the frame, rather than unvoiced. The probability that the frame is from a voiced region of speech can be used directly as the scaling parameter.", "After the scaling parameter has been determined or while it is being determined, the Mel spectra for the vector of harmonic component samples and the vector of random component samples are determined at step 1014. This involves passing each vector of samples through a Discrete Fourier Transform (DFT) 918 to produce a vector of harmonic component frequency values 922 and a vector of random component frequency values 920. The power spectra represented by the vectors of frequency values are then smoothed by a Mel weighting unit 924 using a series of triangular weighting functions applied along the Mel scale. This results in a harmonic component Mel spectral vector 928,", "At step 1016, the Mel spectra for the harmonic component and the random component are combined as a weighted sum to form an estimate of a noise-reduced Mel spectrum. This step is performed by weighted sum calculator 930 using the scaling factor determined above in the following equation:", "After the noise-reduced Mel spectrum has been calculated at step 1016, the log 932 of the Mel spectrum is determined and then is applied to a Discrete Cosine Transform 934 at step 1018. This produces a Mel Frequency Cepstral Coefficient (MFCC) feature vector 936 that represents a noise-reduced speech signal.", "A separate noise-reduced MFCC feature vector is produced for each frame of the noisy signal. These feature vectors may be used for any desired purpose including speech enhancement and speech recognition. For speech enhancement, the MFCC feature vectors can be converted into the power spectrum domain and can be used with the noisy air conduction signal to form a Weiner filter.", "Although the present invention has been described with reference to particular embodiments, workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention."], "tags": ["G10L"]}, {"docid": "EP1707783A1", "paras": ["The present invention is concerned with improvements in or relating to direct injection internal combustion engines and particularly, but not exclusively, to a direct injection internal combustion engine and a combustion method therefor. The invention also relates to a piston suitable for use in a direct injection internal combustion engine and combustion method.", "In many spark-ignition, direct-injection, and internal combustion engines, a fuel injection valve and a spark plug are positioned adjacent to each other around the centre of each combustion chamber in order to provide an optimum fuel-air mixture or combustivity. With such an arrangement, the density of the fuel is relatively great at the discharge electrodes of the spark plug, thereby causing problems such as shortening the life of the spark plugs due to smouldering of their electrodes, or the generation of smoke due to ignition failure.", "It is an aim of the invention to address this problem. Other aims and advantages of the invention will become apparent from the following description, claims and drawings.", "Aspects of the invention therefore provide an engine and a method as set out in the appending claims.", "According to another aspect of the invention there is provided a piston for use in a cylinder of a direct-injection internal combustion engine, the piston having a crown surface and a cavity formed therein wherein the cavity is arranged to deflect fuel injected into the cylinder generally away from the piston thereby to create a stratified fuel-air mix within the cylinder.", "According to another aspect of the invention there is provided a direct-injection internal combustion engine comprising a cylinder, a fuel injection valve for injecting fuel toward a cavity formed in a crown surface of a piston received in the cylinder, a spark plug having a discharge electrode portion disposed in a proximal area of the fuel injected by the fuel injection valve, an operating condition sensor for detecting an engine operating condition; and a control device for controlling the amount of fuel injected by the fuel injection valve, fuel injection timing, and ignition timing of the spark plug based on the detected operating condition, wherein the control device is configured to control the fuel injection timing so that the fuel inverted from the cavity reaches the proximity of the discharge electrode portion later than the time of ignition.", "According to another aspect of the invention there is provided a direct-injection internal combustion engine comprising a cylinder, a fuel injection valve for injecting fuel toward a cavity formed in a crown surface of a piston received in the cylinder, a spark plug having a discharge electrode portion disposed in a proximal area of the fuel injected by the fuel injection valve, an operating condition sensor for detecting an engine operating condition, and a control device for controlling the amount of fuel injected by the fuel injection valve, fuel injection timing, and ignition timing of the spark plug based on the detected operating condition, wherein the control device is configured to control the fuel injection timing so that fuel injection is completed at approximately the same time of ignition by the spark plug.", "In one embodiment, the cavity is arranged such that the discharge electrode portion of the spark plug is positioned inwardly of the cavity area formed by a lateral wall of the cavity when viewed in the axial direction of the cylinder.", "In one embodiment a lateral or side wall of the cavity is approximately parallel to the cylinder axis. Alternatively, the lateral or side wall of the cavity may be slanted toward a sidewall of the cylinder from a bottom side of the cavity.", "In one embodiment, the fuel injection valve is disposed such that the centre or central axis of the fuel injected thereby is approximately parallel to the cylinder axis.", "The fuel injection valve may be disposed such that it approximately coincides with the centre of the cavity when viewed in the direction of the cylinder axis.", "In one embodiment, an annular secondary cavity is provided around the circumference of the cavity formed in the crown surface of the piston.", "In one embodiment a lateral or side wall of the secondary cavity is approximately parallel to the cylinder axis.", "In one embodiment, the ignition timing is configured to effect ignition within the period of fuel injection.", "The fuel injection valve may include a multiple-aperture nozzle portion for injecting fuel in a radial pattern along a virtual circular cone with the nozzle portion as the apex.", "In one embodiment, the discharge electrode of the spark plug is disposed between two adjacent lobes of fuel from among the multiple lobes of fuel injected from the multiple-aperture nozzle portion.", "According to a further aspect of the invention there is provided a combustion method for a direct-injection internal combustion engine comprising injecting fuel that is supplied from a fuel injection valve to a cavity provided at a crown surface of a piston, deflecting the fuel entering the cavity upwardly along a cavity lateral wall to a discharge electrode portion and carrying out ignition before the fuel reaches proximity to the discharge electrode of a spark plug.", "According to a still further aspect of the invention there is provide a combustion method for a direct-injection internal combustion engine comprising injecting fuel that is supplied from a fuel injection valve to a cavity provided at a crown surface of a piston and completing fuel injection at approximately the same time of ignition of a spark plug provided within the internal combustion engine.", "According to another aspect of the invention there is provided a combustion method for a direct-injection internal combustion engine comprising a fuel injection valve for injecting fuel toward a cavity provided at a crown surface of a piston, and a spark plug having a discharge electrode portion disposed in a proximal area of the fuel mist injected by the fuel injection valve; the method comprising injecting fuel supplied from the fuel injection valve to the cavity, deflecting the fuel entering the cavity upwardly along a lateral wall of the cavity to the discharge electrode portion; and carrying out ignition before the fuel reaches proximity to the discharge electrode of the spark plug.", "According to yet another aspect of the invention there is provided a combustion method for a direct-injection internal combustion engine comprising a fuel injection valve for injecting fuel toward a cavity provided at a crown surface of a piston, and a spark plug having a discharge electrode portion disposed in a proximal area of the fuel injected by the fuel injection valve, the method comprising injecting fuel supplied from the fuel injection valve to the cavity and completing the fuel injection at approximately the same time as ignition of the spark plug.", "In one embodiment the ignition timing is so configured that ignition selectively occurs within the period of fuel injection.", "In embodiments of the invention a direct-injection internal combustion engine includes a fuel injection valve that injects fuel toward a cavity provided at the crown surface of a piston. A spark plug is disposed so that its discharge electrode portion is in the proximal area of the fuel from the fuel injection valve. An operating condition sensor detects the engine operating condition; and a control device regulates the amount of fuel injected by the fuel injection valve, the injection timing and the ignition timing of the spark plug based on the detected operating condition. The control device is arranged so that the timing of fuel injection is such that the fuel inverted by the piston cavity reaches proximity with the discharge electrode portion later than the time of ignition.", "The various aspects, embodiments or alternatives set out in the preceding paragraphs, in the claims and in the following description may be implemented individually or in combination.", "The present invention will now be described, by way of example only, with reference to the accompanying drawings in which:", "Throughout the drawings, as far as possible, like reference numerals indicate like parts.", "FIG. 1 schematically shows a partial structure of an internal combustion engine. The internal combustion engine as a whole is shown generally at 1 whilst there is also shown an inlet path 2, a throttle valve 3, an exhaust path 4, a catalytic converter 5, an inlet valve 6, an exhaust valve 7, a fuel injection valve 8, and a spark plug 9. Also shown in FIG. 1 are a control unit 10, an air flow sensor 11, an accelerator aperture sensor 12, a crank angle sensor 13, a coolant temperature sensor 14, and an exhaust oxygen sensor 15. A fuel pump 17 feeds fuel under pressure to the fuel injection valve 8 by cam driving and a pressure sensor 16 detects the fuel pressure.", "The control unit 10 preferably comprises a microcomputer that includes a CPU and peripheral devices. The control unit 10 determines the operating conditions of the internal combustion engine based on input from each of sensors 11 to 16, which are detection devices for the operating conditions, and controls operation of the fuel pump 15, fuel injection valve 8 and spark plug 9 so that the injection timing for the fuel, the amount of fuel injected and the ignition timing match predetermined target values for each.", "FIGS. 2A and 2B show in greater detail the structure of the periphery of a combustion chamber within a cylinder of the internal combustion engine. Represented in these figures are a combustion chamber 21, a cylinder head 22, a cylinder block 23 and a piston 24.", "The illustrated internal combustion engine is a four-valve type, each combustion chamber 21 thereof having two each of inlet valves 6 and two exhaust valves 7. The fuel injection valve 8 and spark plug 9 are provided in the proximity of, and/or are substantially aligned with, the centre of the combustion chamber 21 and are surrounded by the above-mentioned four valves 6 and 7.", "The fuel injection valve 8 is so disposed that the centre of the fuel is substantially aligned with, and/or approximately parallel to, the cylinder axis. A circular cavity 31 is formed on the crown surface of the piston 24 so that it faces the fuel injection valve 8. An annular secondary cavity 32 is formed about the circumference of the cavity 31. In the illustrated embodiment, the lateral or side walls 31a and 32a of each cavity 31, 32 form an approximately orthogonal cylindrical shape parallel to the cylinder axis. However, the lateral walls 31a and 32a may be tapered, for example slanted outwardly toward the cylinder sidewall.", "As shown in FIG. 3, the centres Pa of the cavities 31 and 32 are located slightly offset relative to the cylinder central axis Pb, and due to this configuration, the fuel from the fuel injection valve 8 collides with the approximate centre portion of the cavity 31. The spark plug 9 is arranged so that it serves as a spray guide in which its discharge electrodes 9a (see FIG. 4) are positioned inside the cavity area formed by the cavity lateral wall 31a, viewed from the direction of the cylinder axis. For example, the discharge electrodes are aligned with at least part of the cavity 31. Also, the spark plug 9 is adjacent to the fuel from the fuel injection valve 8.", "FIGS. 4A and 4B show the condition of the fuel when the direct-injection internal combustion engine having the above-mentioned structure is driven using a stratified combustion method, FIG. 4A showing the condition during the first half of the period of injection and FIG. 4B showing the condition during the second half of the period of injection. Fuel injection is carried out to effect stratified combustion as the piston is rising during the second half of the compression process. Fuel is injected from the fuel injection valve 8, as shown in FIG. 4A, toward the approximate centre of the internal cavity 31 so that the entire amount of the fuel is directed toward the cavity 31.", "The injected fuel strikes the bottom surface of the cavity 31 and is diffused in the peripheral direction. In other words, having struck the bottom surface of the cavity 31, the fuel spray spreads radially outwardly towards the side wall 31a of the cavity. The fuel is then guided by the lateral wall 31a of the cavity and is diverted or deflected upwardly towards the upper region of the combustion chamber 21. In other words, the fuel injected into the cylinder towards the cavity 31 is reflected or inverted back towards the fuel injection valve 8 and the spark plug 9.", "During this process, the injected fuel is mixed with atmospheric air, and therefore the fuel travelling upwardly forms an approximately annular or cylindrical mixed fuel-air mass M that conforms substantially to the circumferential shape of the cavity 31 (see FIG. 4B).", "In the illustrated embodiment, the fuel injection valve 8 is disposed such that the central axis of the annular mixed fuel-air mass M is generally parallel to the cylinder axis and substantially aligned with the centre Pa of the cavity 31. Therefore, the formation of the annular mixed fuel-air mass M by the cavity 31 can be evenly carried out in a stable manner regardless of fuel injection timing or the position of the piston and, consequently, is effective in avoiding unburned HC or smoke generation.", "The annular mixed fuel-air mass diffuses in the inward and outward radial directions, as the piston 24 rises, and reaches the discharge electrode portion 9a of the spark plug. In the present engine, ignition is carried out before the stratified mixed fuel-air mass having high fuel density reaches the discharge electrode portion 9a. In other words, when the ignition timing is used as an index, the fuel injection is carried out with timing such that the fuel-rich mixture formed after fuel injection has not yet reached the discharge electrode portion 9a of the spark plug at the time of ignition. This avoids rich combustion at the periphery of the discharge electrode portion 9a of the spark plug, thereby preventing the spark plug from generating smouldering or smoke.", "In the illustrated embodiment, the discharge electrode portion 9a of the spark plug is disposed as closely as possible to the fuel injection valve 8 in the interior of the cavity 31. In other words, it is disposed to be at the approximate centre of the annular mixed fuel-air mass, and therefore it can prolong the period during which the mixed fuel-air mass diffuses radially inwardly of the combustion chamber to reaches the discharge electrode portion 9a, or it can extend the distance between the mixed fuel-air mass and discharge electrode portion 9a. By doing so, the fuel density of the mixed fuel-air mass around the discharge electrode portion 9a at the time of ignition can be reduced and the degree of flexibility for fuel injection timing can be increased.", "In addition, disposing the discharge electrode portion 9a of the spark plug as described above reduces the radius of the mixed fuel-air mass by some portion, and therefore stratified combustion with improved fuel consumption rate can be carried out during idling or under low-load operating conditions. However, when the diameter of the cavity 31 is reduced in order to form a mixed fuel-air mass having a small diameter, the injected fuel overflows around the circumference under mid- to high-load operating conditions, and may interfere with stratification of the mixed air. In anticipation of this condition, the present embodiment includes a second cavity 32 surrounding the cavity 31, and therefore fuel overflowing from the primary cavity 31 can be trapped by the secondary cavity 32 and diffusion of the fuel-air mixture can be prevented. Consequently, stratified combustion can be carried out over a wider operating range.", "Depending on the operating conditions, the mixed fuel-air mass formed by the internal cavity 31 becomes too rich and smoke and unburned HC may be generated. To counter this, the cavity lateral wall portion 31a is tapered so that it increases in diameter in the direction of the combustion chamber and therefore compensates for the tendency of the fuel to be concentrated at the centre portion of the combustion chamber. Therefore, it is possible to make adjustments so that a mixed fuel-air mass having an appropriate fuel density can be formed. Such an adjustment of the fuel density by using the angle of the gradient of the cavity external wall is also effective when applied to the external secondary cavity 32. In other words, the size and density of the stratified mixed fuel-air mass under mid- to high-load operating can be adjusted by means of the above-mentioned angle of the gradient.", "The ignition timing described above, in which the mixed fuel-air mass formed by the cavities 31 and 32 reaches the discharge electrode portion 9a of the spark plug can be, according to experimentation, configured to be near to the completion time of the fuel injection. In particular, if it occurs prior to completion of the injection, the fuel, immediately after the injection but before diffusing, is present in proximity to the discharge electrode portion 9a, and therefore a preferable ignition and combustion can be expected.", "FIGS. 5A shows relative dispositions of the fuel injection valve 8 and spark plug appropriate for carrying out ignition with the above-described timing. FIG. 5A also shows a perspective view of an example of the fuel formation. FIG. 5B is a plan view in the axial direction around the discharge electrode portion 9a of the spark plug. In this case, as shown in FIG. 5A, the fuel injection valve 8 is a multiple-aperture nozzle in which the fuel is injected in a radial pattern along a virtual circular cone surface 33 with the nozzle portion 8a as the apex.", "As shown in FIG. 5B, the discharge electrode portion 9a of the spark plug is disposed at the centre between two adjacent lobes of fuel from among the multiple (in this case, eight) lobes of fuel injected by the multiple-aperture nozzle. The fuel does not directly come in contact with the discharge electrode portion 9a of the spark plug, and therefore, even if ignition is carried out during fuel injection, so-called fogging of the spark plug does not occur, and in addition, ignition can be carried out in the mixed atmosphere of high fuel density close to the fuel, and therefore optimal ignition and combustion can be secured. In addition, the multiple-aperture nozzle can form a fuel formation having a less tapered or modified shape even in a high-pressure cylinder during the latter half of the compression process, and consequently a more stable ignition performance can be obtained.", "FIGS. 6 and 7 show second and third embodiments, respectively, of the present internal combustion engine. The first embodiment described above is provided with a double cavity structure in which a second cavity 32 surrounds a primary cavity 31 having a relatively small diameter. The present engine is not so limited to may have a single cavity structure as shown in FIGS. 6 and 7. FIG. 6 shows a structure in which the lateral wall portion 31 a of the cavity 31 is formed in the shape of an orthogonal cylinder surface parallel to the cylinder axis, and FIG. 7 shows one in which the lateral wall 31 a is formed with a tapered shape by forming an angle so that its diameter increases in the direction of the combustion chamber.", "According to the second embodiment having a cavity formed with an orthogonal cylindrical lateral wall portion 31a as shown in FIG. 6, the deflected direction of the fuel in the cavity 31 is approximately parallel to the cylinder axis and therefore, a mixed fuel-air mass can be formed with a stable size regardless of the position of the piston. In contrast, according to the third embodiment having a cavity formed with a tapered lateral wall portion 31a as shown in FIG. 7, the direction of diffusion of the mixed fuel-air mass deflected by the surface of the cavity 31, and the time in which the mass reaches the discharge electrode portion 9a of the spark plug can be adjusted to correspond to the fuel injection timing. By taking advantage of these properties, a stratified combustion can be carried out over a wide operating range with a single cavity structure, and at the same time, the effect of the present engine described above can be realized.", "While the present direct-injection internal combustion engine has been described in connection with certain specific embodiments thereof, this is by way of illustration and not of limitation, and the appended claims should be construed as broadly as the prior art will permit.", "This application claims priority from"], "tags": ["F02D"]}, {"docid": "EP1443374A2", "paras": ["The invention relates to a technology of obtaining an object workpiece by working a work material in a way that controls a cutting machine on the basis of design information defined on a computer.", "There has hitherto been known a device contrived to automatically perform working by controlling a working machine on the basis of CAD data, etc.. For instance, there is proposed a control device for a machine tool that includes tool route determining means for: inputting workpiece data about workpiece configuration data concerning a final workpiece configuration and workpiece data about a material and a configuration of the workpiece; generating a workpiece working tool route on the basis of data stored with machine s data containing characteristics of a machine body such as a column, a bed, etc. of the machine tool, and tool s data about a working tool which contain a deformation, etc. at a working time when this tool is attached to a holder; and determining working conditions such as a rotating speed of a main shaft, a feeding speed, etc. of the machine tool.", "In the conventional device, a working process is determined by a predetermined algorithm which involves using generally three-dimensional CAD data and databases, thereby actualizing automation and standardization. In this case, contents of the database are not automatically updated unless a man changes them, and a result of working is not reflected in the contents of the database. Further, for adjusting the working process outputted from a system, it was required that a man having special knowledge adjusts the database.", "Therefore, a so-called condition library is main as the database, and there was no system having, as intra-system function, a role performed by an operator such as optimizing the conditions and storing working phenomena, and automatically generating NC data by optimally combining these pieces of information.", "Further, as to a so-called feedback system, there exists a working condition correcting device for measuring dimensions of a plurality of workpieces, obtaining an error between a value of this time and a value of the last time of a specified value thereof, and correcting it, however, there exists none of devices used for correcting a feed and the number of revolutions of a working machine in real time while monitoring a main shaft load and working phenomena such as a chatter, etc. during cutting of one workpiece or for correcting the cutting conditions when working next time.", "Moreover, in a conventional working control device, a feedback of the result of working to the database is intended for what can be expressed as a measured numerical value such as the number of revolutions, a feed speed, a working time, a dimensional accuracy, etc., wherein an intention and a judgment of the operator is not reflected therein as in a case where if preferable of fitting to other parts, an acceptance is gained even when, for instance, the measured value deviates from a dimensional tolerance, and a case where it is sufficient if a molding product is separable from a die even when the surface roughness of an insert part of a molding portion is rougher than a designated value in a resin molding product die assembly.", "Moreover, the tool and the process have hitherto been determined from an experience of the operator. In a three-dimensional CAM that is widely utilized at the present, it is not yet automated as to which tool is used and which process this tool is used.", "Note that there was proposed a system having a function of designing the working process based on the database stored with a type of a product to be worked, a tool and a process in a way that makes them mapping to each other, however, there is not any system for designing the working process from a tool library retaining a given 3D configuration without having such a type of database.", "Further, a system exists, wherein a small tool is determined by calculating a cutting quantity and a cutting residual in sequence from the largest diameter, however, there is no system for calculating a maximum tool diameter that should be used, from a minimum tool diameter that is to be used by the operator for finishing, and a great deal of experiences of the operator were needed.", "In the devices described above, the following problems are pointed out.", "The invention was made to solve the problems given above. Namely, the invention aims at providing a technology enabling the working under proper working conditions by searching for a working case corresponding to characteristics of a configuration to be worked and setting the working conditions based on this working case.", "The invention adopted the following means in order to accomplish the object.", "In a working control device, a working control program and a working control system of the invention, configuration information about characteristics of a three-dimensional configuration is obtained from design data of an object workpiece, a working case is searched out based on the configuration information from a working case storage unit for storing working conditions, as a working case, of the working conducted in the past, working conditions are determined based on the working case searched out by the case searching unit, and a working machine is controlled based on the working conditions.", "A contrivance of the invention is, putting an emphasis on similarities of a working tool, a working process, further, a behavior of a cutting tool during the working and a result of the working if there are similarities in configuration between design data of the object workpiece that should be worked and the working cases conducted in the past, that the working case is accumulated and searched out based on characteristics of the configuration, and the working conditions are determined based on this working case, whereby a result of the working in the past can be utilized. Namely, even a less-experienced operator can perform the working based on the past examples accumulated on a database. Moreover, failure cases can be accumulated together with successful cases after the cutting/working, and it is therefore possible to prevent similar failures from being repeated.", "The invention may also be a recording medium in such a form that the program is recorded on a readable-by-computer recording medium. Then, the computer reads and executes the program on this recording medium, whereby the functions thereof can be provided.", "Herein, the readable-by-computer recording medium connotes a recording medium capable of accumulating information such as data, programs, etc. electrically, magnetically, optically and mechanically or by chemical action, which can be read from the computer. What is demountable out of the computer among those recording mediums are, e.g., a flexible disk, a magneto-optic disk, a CD-ROM, a CD-R/W, a DVD, a DAT, an 8mm tape, a memory card, etc..", "Further, a hard disk, a ROM (Read Only Memory) and so on are given as recording mediums fixed to the computer.", "As explained above, the invention enables the working under the proper working conditions by searching for the working case in accordance with the characteristics of the configuration to be worked and setting the working conditions based on this working case.", "A working system will be explained based on drawings in FIGS. 1 through 35 by way of embodiments of the invention.", "FIG. 1 is a block diagram showing an architecture of the working system in an embodiment.", "The working system in the embodiment is constructed of a working control device 1 and a working machine 2 controlled by this working control device 1.", "The working control device 1 includes a pre-working input unit 11, a three-dimensional configuration characteristic extraction unit (corresponding to a configuration characteristic extraction unit) 12, a case searching unit 13, a cutting working condition auto setting unit (corresponding to a working condition setting unit) 14, a cutting working case database (corresponding to a working case storage unit) 15, a judgment criterion database (corresponding to a judgment criterion storage unit) 16, a working case registration unit 17, a post-working input unit 18, an auto NC data creating unit (control unit) 19, and a monitoring unit 10.", "This pre-working input unit 11, which is an operation unit such as a keyboard, a touch panel, etc. and is operated by an operator, accepts an input of information(object workpiece information) about an object workpiece. The information about the object workpiece is information that is not contained in design data among pieces of data necessary for working, such as a classification, rigidity, etc. of a work material.", "The three-dimensional configuration characteristic extraction unit 12, as will be described later on, obtains configuration information on characteristics of a three-dimensional configuration from three-dimensional CAD data (corresponding to design data) of the object workpiece).", "The case searching unit 13 searches out a working case from the cutting working case database 15 on the basis of the configuration information obtained by the three-dimensional characteristic extraction unit 12.", "The cutting working condition auto setting unit 14 determines working conditions based on the working case searched out by the case searching unit 13.", "The cutting working case database 15 is stored with working conditions, as working cases, of the workings conducted in the past.", "The judgment criterion database 16 is stored, as information serving as judgment criteria for the working conditions, with a working condition threshold value database 16a, a tool library 16b, a cutting condition database 16c, etc..", "The working case registration unit 17 stores the working case storage unit with information of the working machine 2 that has been acquired by the monitoring unit 10 in a way that makes it as a working case mapping to the configuration information.", "The post-working input unit 18, which is an operation unit such as a keyboard, a touch panel, etc. and is operated by the operator, accepts an input of information about whether the working is preferable or not. Note that one single keyboard serves as both of the pre-working input unit 11 and the post-working input unit 18 in the embodiment.", "The auto NC data creating unit 19 controls the working machine 2 on the basis of the working conditions set by the cutting working condition auto setting unit 14.", "The monitoring unit 10 acquires the information of the working machine 2 when the auto NC data creating unit 19 performs controlling based on the working conditions.", "The working control device 1 may be a dedicated electronic device constructed of electronic circuits (hardware) designed exclusively as the respective units 10 ~ 19, and may also be a device in which the functions of the respective units 10 ~ 19 are actualized softwarewise on a general-purpose computer.", "Note that the working control device 1 in the embodiment is, as shown in FIG. 2, a general type of computer.", "As illustrated in the same Figure, the working control device 1 includes, within a main body 31, an arithmetic processing unit 32 constructed of a CPU (central processing unit), a main memory, etc., a storage device (hard disk) 33 stored with data and software for the arithmetic processes, an input/output unit (I/O) 34 and so on.", "Connected properly to the input/output unit 34 are an input device such as a keyboard (the pre-working input unit 11, the post-working input unit 18), the mouse, etc, an output device such as a display device, a printer, etc., and an interface for transmitting and receiving the information to and from other devices.", "An operating system (OS) and application software (a working control program) are installed into the storage device 33. Further, the cutting working case database 15 and the judgment criterion database 16 are built up in the storage device 33.", "The arithmetic processing unit 32 executes the arithmetic processes according to the working control program, thereby functioning as the three-dimensional configuration characteristic extraction unit (corresponding to the configuration characteristic extraction unit) 12, the case searching unit 13, the cutting working condition auto setting unit 14, the working case registration unit 17, the auto NC data creating unit 19 and the monitoring unit 10.", "The working machine 2 in the embodiment includes a cutting working unit 21, a working machine control unit 22 and a magazine 23.", "This cutting working unit 21 is constructed of an installation base for attaching a work material, a cutting tool, a main shaft for fitting this tool, a rotation driving unit for the main shaft, a feed driving unit for feeding in X-axis, Y-axis and Z-axis directions, etc., and performs cutting/working of the work material.", "The working machine control unit 22 controls the cutting working unit 21 on the basis of NC data. This working machine control unit 22 includes a sensor unit 22A for detecting a working state of the working machine 2, a cutting control unit 22B for controlling the cutting working unit 21 in accordance with the working state detected by the sensor unit 22a and the NC data, a magazine management unit 22c for giving an instruction of acquiring information of the tool housed in the magazine and an instruction of replacing the tool, and so on.", "The magazine 23 houses the tool used in the cutting working unit 21. Further, the magazine 23 has a function (ATC) of replacing the tool used in the cutting working unit 21 in accordance with the NC data.", "Next, working control procedures in the system will be described by use of FIGS. 3 ~ 35.", "In the working control device 1, upon an input of three-dimensional CAD data 100 of an object workpiece, as shown in FIG. 3, the three-dimensional configuration characteristic extraction unit 12 obtains configuration information about characteristics of a three-dimensional configuration from the three-dimensional CAD data 100 in step S1.", "Further, the operator inputs pieces of object workpiece information such as a classification, a rigidity of the work material by operating the pre-working input unit 11 in step S2, the pre-working input unit 11 accepts this input and inputs it to the case searching unit 13.", "In next step S3, the case searching unit 13 searches out a working case from the cutting working case database 15 with the configuration information being as a search key.", "In next step S4, the cutting working condition auto setting unit 14 judges whether or not the working case was obtained in step S3, moves to step S5 if obtained, and determines working conditions based on this working case and the information in the judgment criterion database 16. Moreover, if the working case was not obtained in step S3, moving to step S6, wherein the cutting working condition auto setting unit 14 determines the cutting working conditions on the basis of the configuration information obtained by the thee-dimensional configuration characteristic extraction unit 12, the information accepted by the pre-working input unit 11 and the information in the judgment criterion database 16. Herein, the cutting condition database 16c of the judgment criterion database 16 is previously stored with maker recommendation values and default values of the working conditions in accordance with the three-dimensional configuration and the classification of the work material. The cutting working condition auto setting unit 14, if unable to obtain the working case, determines the working conditions by referring to the maker recommendation values and the default values in accordance with the configuration information, etc..", "In next step S7, the auto NC data creating unit 19 creates NC data based on the working conditions determined by the cutting working condition auto setting unit 14, and transmits the NC data to the working machine 2 via the interface of the I/O 34. On the other hand, the working machine 2 effects, based on the NC data, the cutting/working.", "In next step S8, the monitoring unit 10 receives the information detected by the sensor unit 22a and monitors the working state in the working machine 2.", "The auto NC data creating unit 19, in step S9, judges whether the working control is finished or not, repeats steps 7 and 8 if not finished, and moves to step S10 if finished.", "In step S10, the working case registration unit 17 registers, in the cutting working case database 15, the information (working conditions) as a working case that has been detected by the monitoring unit 10 in a way that makes it mapping to the configuration information inputted to the cutting working condition auto setting unit 14 on the occasion of performing this working and to the information inputted from the pre-working input unit 11.", "Thus, the working control device 1 in the embodiment determines the working conditions based on the working case and is therefore contrived so that even a less-experienced operator can do the same working as a well-experienced person does. Further, the working control device 1 registers the result of working in the cutting working case database 15, and hence the result of working can be shared with other persons.", "Next, details of the working procedures will be explained. All of these procedures must not necessarily be executed and may be executed by arbitrarily combining the required procedures on the occasion of working in the working system.", "FIG. 4 is an explanatory chart of a procedure in which the three-dimensional configuration characteristic extraction unit 12 extracts dimensions of a maximum external configuration as configuration information from the three-dimensional CAD data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 divides, based on the three-dimensional CAD data 100, surfaces of a three-dimensional model (an object workpiece) into, as shown in FIG. 5A, minute polygonal shapes (triangles in this example, which will hereinafter be called facets) (step S11, which will hereinafter be abbreviated such as S11), thereafter, as shown in FIG. 5B, obtains X-coordinates, Y-coordinates and Z-coordinates (Fn (Xn, Yn, Zn), Fn+1 (Xn+1, Yn+1, Zn+1), Fn+2 (Xn+2, Yn+2, Zn+2)...) of three vertexes of the facet, and repeatedly performs the same calculation with respect to all the facets (S12 ~ 14). The three-dimensional configuration characteristic extraction unit 12 obtains the X-coordinates, Y-coordinates and Z-coordinates of the vertexes of all the faces and acquires the minimum X-coordinates, Y-coordinates and Z-coordinates and the maximum X-coordinates, Y-coordinates and Z-coordinates by making comparisons between the coordinates of the vertexes of all the facets (S15, S16).", "The three-dimensional configuration characteristic extraction unit 12 subtracts the minimum X-value from the maximum X-value obtained as above, and similarly makes the calculations with respect to the Y-coordinates and the Z-coordinates (S17), thereby obtaining, as shown in FIG. 6, a maximum X-directional length, a maximum Y-directional length and a maximum Z-directional length of the three-dimensional model and setting them as maximum external configuration dimensions (configuration information) (S18).", "FIG. 7 is an explanatory chart of a procedure in which the three-dimensional configuration characteristic extraction unit 12 acquires a removal volume as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 divides the surfaces of the three-dimensional model (FIG. 8A) represented in the three-dimensional CAD data 100 into facets as shown in FIG. 8B (S21), thereafter creates triangles by projecting, as illustrated in FIG. 8C, the respective facets on an X-Y plane, i.e., a fitting surface to the working machine (S22), connects the facets to corresponding vertexes of the triangles formed by projecting the facets onto the X-Y plane (S23), obtains a volume of a triangle pole (FIG. 8D) configured by three sides of the facet, three sides of the triangle formed by projecting the facet onto the X-Y plane, and three line segments that connect the facet to corresponding vertexes of the triangle formed by projecting the facet onto the X-Y plane (FIG. 8D)(S24), obtains volumes with respect to all the facets by repeating this (S25), and thus calculates a total sum of the volumes, i.e., a value of the three-dimensional model (S26).", "Thus, after calculating the volume of a three-dimensional model 91 in FIG. 9A, as described above, a maximum X-directional length, a maximum Y-directional length and a maximum Z-directional length are obtained with respect to the 3-cutting working unit 21, a maximum model external configuration volume is obtained by multiplying the maximum X-directional length, the maximum Y-directional length and the maximum Z-directional length (S27), and a volume of the 3-cutting working unit 21 is subtracted from this maximum external configuration volume, thereby acquiring a volume removed by the cutting/working as shown in FIG. 9B (S28).", "FIG. 10 is an explanatory chart of a procedure in which the three-dimensional configuration characteristic extraction unit 12 acquires surface information as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 divides, based on the three-dimensional CAD data 100, surfaces of a three-dimensional working configuration into facets (S31, and thereafter, as shown in FIG. 11, obtains normal line vectors of all the facets (S32). The three-dimensional configuration characteristic extraction unit 12 judges whether or not the normal line vectors (directions) of these facets are parallel with the Z-axis, i.e., a working axis (S33), obtains areal sizes of the facets and Z-values about only the facets showing the parallelism (S34, S35), sorts out the areal sizes per Z-value (S36), and acquires the surface information, according to the Z-values, of the flat surfaces parallel with the X-Y plane (S37). Note that the facets of which the normal line vectors are judged not to be parallel with the working axis in step S33 are excluded from the information (S38).", "As for a surface, perpendicular to the working axis, in the three-dimensional model, viz., the surface that can be machined by a flat end mill, an areal size per position in the Z-axis direction, i.e., the areal size presumed so that it can be machined at one time, is thereby acquired; and the cutting working condition auto setting unit 14, on the occasion of determining the working conditions, based on this piece of surface information, selects a tool having a large diameter if the areal size is large and a tool having a small diameter if the areal size is small.", "FIG. 12 is an explanatory chart of a procedure in which the three-dimensional configuration characteristic extraction unit 12 acquires a minimum concave shape radius dimension as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 classifies, based on the three-dimensional CAD data 100, the surfaces of the three-dimensional model into flat surfaces and surfaces other than those, i.e., curved surfaces (S41), extracts surfaces of the curved surfaces (S42), and excludes the surfaces other than those from the information (S48).", "Then, the three-dimensional configuration characteristic extraction unit 12, as shown in FIG. 13A, divides the curved surface respectively in U-and V-directions at an error allowable value interval when creating the three-dimensional model (S43), acquires a radius from three intersections between dividing lines adjacent to each other in the U- and V-directions (S44), as shown in FIG. 13B, obtains a direction of the Z-component of the normal line vector acting outwards from a center of the acquired radius (S45), seeks out whether this direction of the Z-component is coincident with a (-) Z-direction (S46), judges, if not coincident, that it is a convex shape radius and excludes it from the information (S49), then judges, if coincident, that it is a concave shape radius (S46), and acquires a minimum concave shape radius among these radiuses (S47).", "With this, the cutting working condition auto setting unit 14, on the occasion of determining the working conditions, obtains a diameter of the tool used for finishing on the basis of this minimum concave shape radius dimension.", "FIG. 14 is an explanatory chart of a procedure in which the three-dimensional configuration characteristic extraction unit 12 acquires a largest concave shape radius dimension as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 acquires, in the same way as the above-mentioned, the surfaces (FIG. 15A) having the concave shapes (S41 ~ S46 in FIG. 12), obtains, from among these surfaces, a surface configured by sides having the same size and coincident in their directions of the normal line vectors and by two straight lines as shown in FIG. 15B, a surface configured by one pair of face-to-face sides having intersections between the normal line vectors and by one pair of face-to-face sides having intersections between the normal line vectors and having the same radius as shown in FIG. 15C and a surface having intersections between the normal line vectors of four sides as shown in FIG. 15D (S51), then calculates areal sizes of these surfaces (S52), and classifies these surfaces according to sizes of the radiuses. The surface shown in FIG. 15C is, however, classified based on the radius having the same size (S53).", "Then, the three-dimensional configuration characteristic extraction unit 12 obtains an areal size according to every size of the thus classified radius, and acquires the size of the radius with the areal size coming to the maximum, as a largest concave shape radius dimension (S54).", "The cutting working condition auto setting unit 14 thereby acquires, based on this largest concave shape radius dimension, a diameter of the tool used before finishing on the occasion of determining the working condition.", "FIG. 16 is an explanatory view in a case where the three-dimensional configuration characteristic extraction unit 12 acquires a maximum depth as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 divides, based on the three-dimensional CAD data 100, the surfaces of the three-dimensional model into the facets, thereafter acquires, as shown in FIG. 16, Z-axis values of vertexes with respect to the facets configuring a surface perpendicular to the X-Y plane of the cutting working machine 2 and abutting on (coincident in the Z-axis value) the fitting surface to the cutting working machine 2 or a surface containing a circular arc and a surface excluding the fitting surface to the cutting working machine A, and obtains a difference, as a maximum depth, between Zmax, i.e., the maximum Z-axis value and Zmin, i.e., the minimum Z-axis value.", "The cutting working condition auto setting unit 14 thereby selects, mapping to this maximum depth, a tool having such a length as not to interfere with the work material on the occasion of determining the working condition.", "FIG. 17 is an explanatory view in a case where the three-dimensional configuration characteristic extraction unit 12 acquires a cutting range boundary line as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 divides, based on the three-dimensional CAD data 100, the surfaces of the three-dimensional model into the facets, then judges whether a normal line of this facet is perpendicular to the X-Y plane, i.e., parallel with the working axis, and sorts out them into surfaces configured by the facets exhibiting the parallelism and the surfaces containing the facets exhibiting none of parallelisms.", "Then, the surfaces with edges shared in each classification are grouped and thus obtained as a working range, and edges, which are not shared with other surfaces in each of groups, are obtained as working range boundary lines. For example, in FIG. 17, surfaces 41, 42, 43 are grouped, wherein edges that are not shared with other surfaces in this group, i.e., an outer periphery of the group that is drawn by a bold line is obtained as a working range boundary line.", "The cutting working condition auto setting unit 14 thereby determines this working range boundary line and a working range on the occasion of determining the working conditions. Moreover, the cutting working condition auto setting unit 14, depending on whether the surfaces becoming this working range are surface perpendicular to the working axis or not, determines whether they are cut by a flat end mill or a ball end mill.", "FIG. 18 is an explanatory view in a case where the three-dimensional configuration characteristic extraction unit 12 acquires blank dimensions as configuration information from the three-dimensional data 100 in step S1.", "The three-dimensional configuration characteristic extraction unit 12 obtains maximum external configuration dimensions respectively in the X-, Y- and Z-directions in the procedure shown in FIG. 4 in the same way as in the items 2-1 (S11 ~ S18). Then, the three-dimensional configuration characteristic extraction unit 12 searches the working case database 15 for a past cutting working case where the external configuration dimensions are most approximate, then obtains a cutting margin (working margin) from this past working case (S61), temporarily determines the blank dimensions by adding the thus obtained cutting width to the maximum external configuration dimensions (S62), makes a comparison with maximum possible-of-working dimensions of the cutting working machine 2 (S63), and, in the case of judging that the working by the cutting working machine 2 is possible (S64), determines the temporarily determined blank dimensions as (final) blank dimensions as shown in FIG. 19) (S65).", "The working case database 15 is accumulated per working case with: the maximum external configuration dimensions (X, Y, Z), the removal volume, the surface information (about whether the surface is a flat surface parallel with the working X-Y plane or is a non-flat surface), the largest concave shape radius dimension, the minimum concave shape radius dimension and the maximum depth dimension which have been extracted by the three-dimensional configuration characteristic extraction unit 12; the cutting working conditions such as the cutting working step procedure, the classification of the cutting working tool, the set number of revolutions of the main shaft, the feeding speed, the feeding pitch, the Z-cutting quantity, the trajectory of the working tool; the actual number of revolutions of the main shaft, the actual feeding speed, the load on the main shaft in the process of working, the actual cutting time when the cutting/working is actually conducted; the information on a variety of physical phenomena; and the information about whether the cutting/working is judged by the operator to be preferable or not. Note that FIG. 20 is a conceptual diagram of this working case database 15.", "The case searching unit 13 searches this cutting working case database 15 for a working case exhibiting a similar configuration, as shown in FIG. 21, on the basis of pieces of configuration information such as the maximum external configuration dimensions, the removal volume, the surface information, the largest concave shape radius dimension, the minimum concave shape radius dimension and the maximum depth dimension which have been, as described above, acquired by the three-dimensional configuration characteristic extraction unit 12.", "For example, in case a search condition is the maximum external configuration dimension, a dimensional difference is obtained as an absolute value by comparing a maximum X-axis length of the three-dimensional model with a maximum X-axis length in the working case, similarly dimensional differences in Y- and Z-axis directions are obtained, and, if the values in all the X-, Y- and Z-axis directions are equal to or smaller than values (d) predetermined by the system, it is deemed that the maximum external configuration dimensions take a similar configuration.", "Further, in case the search condition is the removal volume, there is obtained a difference in the removal volume (a cutting working volume) between the three-dimensional model and the past working case, and, in a case where an absolute value thereof is equal to or smaller than a value (dV) predetermined by the system, it is deemed that the removal volume is similar.", "In case the search condition is the surface information, there is obtained a difference in the areal size of the flat surface parallel with the X-Y plane between the three-dimensional model and the working case, and, in a case where an absolute value thereof is equal to or smaller than a value (dA) predetermined by the system, it is deemed that the surface information is similar.", "In case the search condition is the largest concave shape radius dimension, there is obtained a difference in the largest concave shape radius dimension between the three-dimensional model and the past working case, and, in a case where an absolute value thereof is equal to or smaller than a value (dR) predetermined by the system, it is deemed that the largest concave shape radius dimension is similar.", "In case the search condition is the minimum concave shape radius dimension, there is obtained a difference in the minimum concave shape radius dimension between the three-dimensional model and the past working case, and, in a case where an absolute value thereof is equal to or smaller than a value (dMR) predetermined by the system, it is deemed that the minimum concave shape radius dimension is similar.", "In case the search condition is the maximum depth, there is obtained a difference in the maximum depth dimension between the three-dimensional model and the past working case, and, in a case where an absolute value thereof is equal to or smaller than a value (dD) predetermined by the system, it is deemed that the maximum depth dimension is similar.", "The case searching unit 13 searches out the working case that meets these search conditions, and, in case the information about whether the working in this working case is preferable or not is acceptable, the cutting working condition auto setting unit 14 determines the cutting working conditions on the basis of the number of working steps, the working tool for use, the feeding speed, the number of revolutions of the main shaft that are stored by way of this working case.", "Note that the cutting working condition auto setting unit 14 may also optimize the cutting working conditions as will be mentioned later on in order to reduce a cutting working time and to improve a working accuracy.", "In case the cutting working case database 15 has a small number of working cases, and in case there are not any work materials and cutting working tools nor combinations thereof that show none of the working cases as a result of the search and a premise is that the ball end mill is employed as the cutting working tool, the cutting working condition auto setting unit 14 determines the cutting working conditions on the basis of standard values stored on the cutting condition database 16c and values indicated by the operator from on the pre-working input unit 11.", "At this time, theoretical surface roughness is, as shown in FIG. 22, expressed by H = R - (R", "Accordingly, the working surface roughness obtained in the cutting working conditions becomes this theoretical surface roughness. Performing the working in fact, however, the actual roughness of the working surface (the actual working surface roughness) might differ depending on a type of the work material, the feeding speed, etc..", "Therefore, the cutting working condition auto setting unit 14 effects, as shown in FIG. 23, a recalculation based on the working condition threshold value database 16a so that the working surface roughness required is to be acquired.", "Note that the working condition threshold value database 16a is stored with a corresponding relation between the actual working surface roughness and the working conditions in the case of coming to this roughness, the relation being obtained from a cutting test, the cutting case and the working data, etc. provided from a maker.", "To start with, the cutting working condition auto setting unit 14 obtains the theoretical roughness (S71), adds a predetermined allowable value to this theoretical surface roughness, and searches the working condition threshold value database 16a for the actual working surface roughness existing in an allowable value range (S72).", "Then, the cutting working condition auto setting unit 14, if the theoretical roughness is not coincident with the actual working surface roughness, searches again with a next candidate tool (S73), and, whereas if coincident, acquires pieces of data of the cutting tool, the work material, the main shaft number-of-revolutions, the feeding speed, the feeding pitch and the actual working surface roughness in this working case. Further, a peripheral speed of the cutting working tool and a feed quantity per edge are obtained by calculation from these pieces of data. Next, the main shaft number-of-revolutions and the feeding speed are obtained by calculations from these calculated values and a diameter of the working tool used for a new working configuration, and results thereof are set as cutting conditions of a new cutting configuration (S74).", "The cutting working conditions in which the working surface roughness required is acquired also in the new configuration having none of the working cases, can be thereby automatically outputted.", "FIG. 24 shows a procedure of control of properly working by monitoring the main shaft load wen working in steps S7 ~ S9.", "The auto NC data creating unit 19 makes the working machine 2 start the working by transmitting NC data creases based on the cutting working conditions given from the cutting working condition auto setting unit 14 to the working machine 2, and simultaneously measures, in the monitoring unit 10, working states (a variety of physical states) of the working machine 2 in real time. At this time, if the main shaft load increases abnormally, this induces a damage to the working machine 2 and deterioration of the cutting workpiece, and therefore the auto NC data creating unit 19 controls so that this main shaft load becomes proper.", "To begin with, the auto NC data creating unit 19 obtains an upper value of main shaft load and a proper value of main shaft load from the working machine control unit 22 or the judgment criterion database.", "Further, the auto NC data creating unit 19 makes the working machine 2 start the working by transmitting the NC data to the working machine 2 (S82), and obtains the main shaft load from the monitoring unit 10.", "At this time, the monitoring unit 10 detects a drive current value (a main shaft power P) of an electric motor for driving the main shaft with the sensor unit 22a, and calculates the actual feeding speed from this current value by use of the following formula 1 (S83).", "The auto NC data creating unit 19 judges whether the working is finished or not (S84), then judges whether or not a main shaft load STR is equal to a proper value ST if not finished (S85), returns to step S82 ad continues the working if equal, obtains, if not equal, such a main shaft power (main shaft electric motor output) P as to become equal thereto (S86), acquires from the formula 1 such a feeding speed as to become this main shaft power P (S87), and transmits such NC data as to become this feeding speed to the working machine 2 (S82).", "Then, in the case of judging that the working is finished (S84), the working case registration unit 17 changes the feed value in the working conditions to a feed value when STR = ST, and registers it in the cutting working case database 15 (S88).", "This, even in a case where the set working conditions are not proper, makes it possible to prevent a damage to the working machine 2 and deterioration of the object workpiece by controlling the feeding speed in real time.", "Further, a consequence of this working are registered as the working result, and hence the working can be carried out with proper values from the beginning when performing the working next time.", "Moreover, this value controlled by monitoring may also be, without being limited to the feeding speed, the main shaft number-of-revolutions, the Z-cutting quantity, the feeding pitched, etc.. Further, these are not singly controlled, but the control items can be also controlled throughout the whole items such as controlling the main shaft number-of-revolutions next to the control of the feeding speed, then controlling the Z-cutting quantity, subsequently controlling the feeding pitch, and so on.", "FIGS. 25 ~ 27 are explanatory diagrams in the case of obtaining the tool diameter based on the cutting range boundary line acquired in the item 2-7.", "The cutting working condition auto setting unit 14, upon acquiring the cutting range boundary line as described above (S101), refers to the tool library 16b, selects the working tool registered in the library 16b in an ascending or descending sequence of the diameter (S102), and disposes it so as to abut at an arbitrary point 51 on the cutting range boundary line as shown in FIG. 25 (S103). Then, the cutting working condition auto setting unit 14 moves the working tool so as to abut at the point 51 on this boundary line at all times (S104), checks whether or not there exists other contact point excluding the point 51 between the tool and the boundary line (S105), and, if it exists, judges whether an angle made by a straight line K1 connecting this point to the center of the working tool and by a normal line K2 across the point on the boundary is 180\u00b0 or not (S106).", "Then, the cutting working condition auto setting unit 14 deems it to be an interference that this angle is an angle other than 180\u00b0, selects, moving back to step S102, a next tool from the tool library, then repeats the processing, judges to be usable without any interference whereas if this angle is 180\u00b0 (S107), and repeats this process till a largest working tool diameter with no interference is acquired (S108).", "FIG. 28 is an explanatory diagram in the case of obtaining a tool protrusion quantity based on the cutting depth acquired in the item 2-6.", "The cutting working condition auto setting unit 14, upon obtaining the cutting range boundary line as described above (S91), acquires a protrusion quantity L required at the minimum from the maximum depth (S92), selects from the tool library a cutting working tool having a protrusion quantity that exceeds this minimum protrusion quantity but is a small protrusion quantity or total length by referring to the tool library 16b (S93), then checks, in the case of combining with a designated holder shape designated from a diameter, etc. of the cutting working tool as shown in FIG. 29 (S94), whether or not the three-dimensional model interferes with this holder-attached cutting working tool (S95), deems it usable if not interfered (S96), and deems it unusable if interfered.", "In the case of being unusable, a tool approximate to the maximum depth and having a small protrusion quantity or total length is next retrieved from the tool library, and similarly the interference check is conducted by combining the designated holder.", "The cutting working condition auto setting unit 14 selects a working tool suited to the working depth by repeating this the working tool selection, the designated holder fitting and the interference check.", "FIG. 30 is an explanatory diagram in the case of obtaining a type of the working tool on the basis of the surface information acquired in the item 2-3.", "The cutting working condition auto setting unit 14 obtains the surface information as described above and classifies them into flat surfaces parallel with the X-Y plane and surfaces unparallel therewith. Then, the cutting working condition auto setting unit 14 selects from the tool library 16C a flat end mill or a bull nose as a tool for working the flat surface parallel with the X-Y plane, and selects from the tool library 16c a ball end mill as a tool for working the flat surface unparallel with the X-Y plane of the working coordinates and a non-flat surface.", "FIG. 31, FIG. 32 are explanatory charts for detecting a tool line-time or breakage.", "The NC data automatically created by the auto NC data creating unit 19 are sent to the working machine control unit 22, and, when the cutting working machine 2 starts working, the monitoring unit 10 measures in real time a variety of physical states in the process of working on the basis of the values detected by the sensor unit 22a.", "The auto NC data creating unit 19 avoids a breakage by controlling the cutting working conditions in real time in accordance with generated ultrasonic waves when a working tool material comes to a breakage among physical phenomena monitored by this monitoring unit 10, or controls the cutting working conditions of the next time in a way that changes the cutting condition database 16c after the cutting/working.", "In the case of controlling the cutting working conditions in real time, the auto NC data creating unit 19, as shown in FIG. 31, at first starts monitoring (step A1, which will hereinafter be abbreviated such as A1), judges whether or not a quantity of ultrasonic waves intrinsic to the working tool material per unit time is equal to or larger than a predetermined value and whether or not a total number of generated ultrasonic waves is equal to or larger than a predetermined value (A3), and, in the case of exceeding this predetermined value, namely, a value from which to enable a prediction of an abnormal abrasion/breakage phenomenon of the working tool that is predetermined from the working test and the cutting/working experience (YES in A2)m or in case the number of generated ultrasonic waves during the cutting/working exceeds a value just before an expiration of the life-time and the breakage of the working tool (YES in A3), transmits an instruction (NC data) with the cutting working conditions changed to the cutting working machine 3 or via the cutting machine control unit 22 to the cutting working machine 2.", "Herein, in case the change in the cutting working conditions is a change in the feeding speed (YES in A4), an instruction of decreasing the feeding speed by a fixed value at a predetermined rate is outputted to the cutting working machine 2 or via the working machine control unit 22 to the cutting working machine 2, and this is repeated till the number of generated ultrasonic waves becomes equal to or smaller than the predetermined value (A5). For example, in a case where the feeding speed has been set at F1000, that is done till it comes to F900. Even by doing so, in case the number of generated ultrasonic waves of the tool cannot be restrained, the feeding speed is decreased stepwise such as F800, F700... during the cutting/working.", "Moreover, in case the change in the cutting conditions is a change in the main shaft number-of-revolutions (NO in A4), an instruction of decreasing the main shaft number-of-revolutions by a fixed value at a predetermined rate is outputted to the cutting working machine 2 or via the working machine control unit 22 to the cutting working machine 2 (A6), further a quantity of the ultrasonic waves per unit time is measured, determining the main shaft number-of-revolutions is repeated, and this is conducted till the number of generated ultrasonic waves becomes equal to or smaller than the predetermined value.", "Furthermore, in the case of changing the cutting condition database 16c after the cutting/working, as shown in FIG. 32, the cutting/working is performed according to the first NC data without changing the cutting conditions during the cutting/working, and the number of generated ultrasonic waves related to the abnormal abrasion/breakage phenomenon that has been monitored is temporarily stored on the storage device 33.", "Then, after the cutting/working has been finished, the monitoring unit 10 judges whether or not the number of generated ultrasonic waves per unit time which has been temporarily recorded on the storage device 33 is equal to or larger than the predetermined value (A10) or whether or not a total number of generated ultrasonic waves is equal to or larger than a predetermined value (A11). In the case of judging in steps A10, A11 that the number of generated ultrasonic waves is equal to or larger than the predetermined value, the monitoring unit 10 judges whether the setting of the cutting condition is the change in the feeding speed or not (A12) and transmits, in the case of the change in the feeding speed, this piece of information to the working case registration unit 17, and the working case registration unit 17 decreases the feeding speed in the cutting condition database 16c by a predetermined value (A13).", "Moreover, if the setting of the change in the cutting conditions is not the change in the feeding speed, it is judged whether or not this is a change in the main shaft number-of-revolutions (A14) or whether this is a changed in the feeding pitch or not (A15), in the case of YES, this piece of information is transmitted to the working case registration unit 17 in the same way as in the case of the feeding speed, and the working case registration unit 17 decreases the main shaft number-of-revolutions in the cutting condition database 16c by a predetermined value (A15) or decreases the feeding pitch by a predetermined value (A17).", "Moreover, in case the setting of the change in the cutting conditions is none of the changes given above, the working case registration unit 17 decreases the Z-cutting quantity in the cutting condition database 16c by a predetermined value (A18).", "As a result, in the setting of the cutting working conditions from the next time onwards, it follows that the working conditions, which this change is reflected in, and the NC data can be outputted.", "The above operations are effected, whereby the cutting working conditions can be automatically controlled so as not to cause the occurrence of the abnormal abrasion of the tool when employing the same type of working tool.", "In the embodiment, the physical phenomenon has been explained as the ultrasonic waves, however, the physical phenomena may be not only the ultrasonic waves but also, if being phenomena detectable by the sensor, sounds or vibrations perceptible to the five senses of a human being, a change in configuration and a suing time of the tool and further physical phenomena unperceptible to the five senses of the human being such as the ultrasonic waves.", "It is general that the cutting/working is conducted by separating it into a plurality of processes such as rough working, intermediate finishing working and finishing working. In this case, to begin with, the cutting is roughly done by a tool for rough working, and next this cutting residual is cut by a tool for the intermediate finishing working. At this time, as shown in FIG. 33A, if a tool C exhibiting an excessive cutting quantity is selected as the tool for the intermediate finishing working, it follows that more of cutting than needed is to be done, resulting in rough finishing. Therefore, it is required that a tool B capable of cutting the cutting residual and cutting to such an extent that the finishing working can be done by the tool A for finishing working as shown in FIG. 33B, be selected. Thus, in the case of selecting the tool, it is desirable that the selection be made taking into account the tools used before and after it.", "Such being the case, in the embodiment, as shown in FIGS. 34, 35, the selection is made in a way that deals with the plurality of tools as a set (FIG. 33C).", "To start with, the three-dimensional configuration characteristic extraction unit 12 of the system extracts the configuration information of the three-dimensional model for performing a working process design (B1). Next, the case searching unit 13 searches the working case database 15 for pieces of configuration information, i.e., the maximum external configuration dimensions, the removable volume, the surface information, the largest concave shape radius dimension, the minimum concave shape radius dimension, the maximum depth and the cutting range boundary line, and searches out a working case in which these pieces of configuration information are coincident within a predetermined allowable range and the working result is preferable (B2).", "The cutting working condition auto setting unit 14 extracts a diameter of a single or a plurality of working tools used in this working case, a working tool holder, a tool material and a type such as a tool edge shape, etc. batchwise as a working tool set, and uses them as initial values in the new working process design (B3).", "Next, the cutting working condition auto setting unit 14 assigns the working process to each of the tools extracted. For example, in case this searched-out working tool set is ball end mills having a diameter of 10 mm, a diameter of 6 mm, a diameter of 3 mm and a diameter of 1 mm, a first working process is assigned to the diameter of 10 mm, a second working process is assigned to the diameter of 6 mm, a third working process is assigned to the diameter of 3 mm, and a fourth working process is assigned to the diameter of 1 mm, thus assigning the working processes to the working tools from the largest diameter of the working tool down to the smallest diameter thereof (B4).", "Next, the cutting working condition auto setting unit 14 obtains a cutting residual quantity per working process assigned, and, if there is a gap between the cutting residual quantity and the allowable range of the next tool, adds tools. A cutting residual volume of an n-th tool is obtained by, for instance, a method or the like of calculating the cutting residual part as shown in FIG. 22, and, if this is a larger than the allowable range (the Z-cutting quantity + a coefficient) of the next tool, an interpolation working process is automatically added to between an n-th working process and an (n+1)th working process subsequent thereto (B5).", "Next, the cutting working condition auto setting unit 14, if the cutting residual quantity is small and falls within the allowable range of the next tool even when there are none of the tools, deletes this tool for efficiency. For example, if the cutting residual quantity of the n-th tool falls within the allowable range of an (n+2)th tool, the (n+1) th tool is deleted (B6).", "Then, the cutting working condition auto setting unit 14 determines the tool set undergoing the execution of this adding/deleting process, as the using tools (B7).", "This makes it feasible to design the working process that automatically uses the proper tools.", "FIGS. 3, 36, 37, 38 are explanatory diagrams of control of determining the tool and the working process from a target time. As shown in the same Figures, the working control device of the invention executes respective steps of a method of determining the tool and the working process in accordance with the working control program (including a tool determining program).", "To begin with, in step 1, the three-dimensional configuration characteristic extraction unit 12 acquires a final configuration (a configuration of an object workpiece) and a blank configuration from three-dimensional CAD data of the object workpiece, and acquires an area, as a removal area, into which the final configuration is removed from the blank configuration. For instance, in FIG. 36A, a solid black area represents the final configuration, a rectangular area drawn by a bold line represents the blank configuration, and a white-base area inside the blank configuration represents the removal area. Note that the blank configuration is acquired from the three-dimensional CAD data in the same way as in the item 2-8 in the embodiment. In the embodiment, the three-dimensional configuration characteristic extraction unit 12 obtains the removal area by removing the final configuration from the blank configuration (namely, a volume of the removal area is obtained by subtracting a volume of the final configuration from a volume of the blank), however, without being limited to this, only the final configuration is obtained in step 1, the blank configuration is inputted in step 2, and the cutting working condition auto setting unit 14 may acquire the removal area by removing the final configuration from the blank configuration in step 5.", "In step 2, the pre-working input unit 11 accepts an input of pieces of object workpiece information such as a classification of a product, a material of the workpiece, etc.. Note that the cutting working case database is previously stored with a cutting quantity (a reference cutting quantity) per unit time which serves as a reference, mapping to the object workpiece information such as the classification of the product, the material of the workpiece, etc..", "In step 3, the case searching unit 13 searches the cutting working case database and thus obtains the cutting quantity mapping to the classification of the product and the material of the workpiece, as a working case.", "In case this working case is searched out (S4), moving to step 5, the cutting working condition auto setting unit 14 determines, based on this working case, the working conditions, i.e., the tool and the working process.", "FIG. 37 is the chart showing in detail a procedure of determining the tool and the working process in step 5.", "As shown in the same chart, the cutting working condition auto setting unit 14 executes steps 501 ~ 508 that follow.", "In step 501, a minimum tool diameter required for the cutting/working is determined based on the information about the usable tool information stored on the tool library and the three-dimensional CAD data. Namely, the minimum concave shape radius dimension is obtained as in the item 2-4 from the three-dimensional CAD data, and, among the diameters of the tools stored on the tool library, a diameter that is equal to or smaller than but most approximate to this dimension is set as the minimum tool diameter.", "The tool library is stored with the tool diameter of the usable tool, the feeding speed, the pitch, the Z-cutting quantity and the cutting quantity per unit time as shown in, e.g., Table 1.", "In step 502, a target time T of the cutting/working is determined based on the working case searched out by the case searching unit 13. Namely, the target time T is calculated by dividing the volume of the removal area by the reference cutting quantity.", "In step 503, a time T1 when the entire removal area is cut by a tool TL1 having the minimum tool diameter, is calculated. That is, the cutting time T1 is obtained by dividing the volume of the removal area by the cutting quantity, per unit time, of the tool TL1.", "In step 504, the target time T is compared with the cutting time T1, and there moves to step 505 if T < T1 and to step 507 if T = T1.", "In step 505, the tools are added in sequence from the tool having the minimum tool diameter, and a cutting time Tn in the case of effecting the cutting/working with the tools inclusive of the n-th tool, is calculated. The tools to be added, which have diameters larger than the diameter of the tool with the cutting time already calculated, are extracted by every predetermined number of pieces from among the usable tools. For instance, if the minimum tool diameter is F1 and if extracted one by one, a tool having a tool diameter of F2 is added as T12. Further, the predetermined number of pieces are stored mapping to the object workpiece information on the cutting working case database and may also be a value searched out mapping to the object workpiece information. For instance, if the classification of the product is a die mold, the extraction is done one by one, and, if being a box body for a personal computer, the extraction is done by every twos.", "Moreover, in step 505, the cutting time Tn is calculated, wherein the cutting/working for the Z-cutting quantity is performed with the tools inclusive of TLn-1 when the n-th tool is set as TLn, and a time for which the residual cutting/working is effected with the tool TLn is set as the time Tn. Namely, in step 503, as indicated by a hatching area in FIG. 36B, the working time when the entire removal area is cut by the tool TL1 is obtained, while in step 505, in the case of adding the second tool TL2, the cutting is conducted with the tool TL1 by the Z-cutting quantity as shown in FIG. 36C (the hatching area), and a time T2 when a residual vertical line area is cut with TL2, is obtained. Moreover, in the case of adding TL3, as shown in FIG. 37C, a time T3 is obtained.", "For example, in the case of working a blank (workpiece) of 100 X 80 X 50 (mm) in a final configuration as shown in FIG. 38A, the minimum tool diameter is set to \u03a61, the tools registered on the tool library shown in Table 1 are added one by one, in the case of working with seven pieces of tools, as shown in FIG. 38B, the cutting/working is effected respectively with the tools of TL1 through TL6 by the Z-cutting quantity, and the residual cutting/working is done with the a tool TL7.", "Table 2 shows volumes cut respectively by the tools TL1 ~ TL8 in the case of performing the working by n-pieces of tools.", "Namely, the cutting time Tn in the case of effecting the cutting/working by each number of pieces is a sum of the time when cut with the tools TL1 ~ TLn-1 by the Z-cutting quantity and the time when the residual cutting is done with the tool TLn. Table 3 shows the cutting time Tn in the case of effecting the cutting/working with each number of pieces.", "In step 506, the cutting time Tn is compared with the target time T, the tool is added if T < Tn, the process (S505) of calculating the cutting time Tn is repeated, and there moves to step 507 if T = Tn.", "In step 507, the using tool is determined from among the n-pieces of tools at a point of time when the cutting time Tn becomes shorter than the target time. Namely, if the cutting time T1 is equal to or less than the target time T, only the tool TL1 is used, and, if equal to or less than the target time T when the cutting time Tn = T5, the using tool is determined from among TL1 ~ TL5. For example, if the target time is 330 sec in an example of the Table 3, the using tool is determined from among TL1 ~ TL7.", "Note that the method of determining the using tool from the plurality of tools is arbitrary, all the tools may be used, and a predetermined number of pieces may also be selected. For instance, in the case of selecting three pieces from among n-pieces of tools (n is three or larger in this case), a tool having the minimum diameter, a tool having the maximum diameter and one piece of tool having an intermediate diameter therebetween are selected. Similarly, in the case of selecting four pieces from among the n-pieces of tools, the tool having the minimum diameter, the tool having the maximum diameter and two pieces of tools having the intermediate diameter therebetween are selected.", "In step 508, the working process is determined in sequence from the largest tool diameter among the selected tools. For example, in case this searched-out working tool set is ball end mills having a diameter of 10 mm, a diameter of 6 mm, a diameter of 3 mm and a diameter of 1 mm, a first working process is assigned to the diameter of 10 mm, a second working process is assigned to the diameter of 6 mm, a third working process is assigned to the diameter of 3 mm, and a fourth working process is assigned to the diameter of 1 mm, thus assigning the working processes to the working tools from the largest diameter of the working tool down to the smallest diameter thereof.", "Then, processes from step 7 onwards are executed by use of the determined tools and the working processes.", "Thus, the tools are added in sequence from the tool TL1 having the minimum tool diameter, the tool Ln when the target time is reached is obtained, and the tools are determined to use TL1 ~ TLn, whereby the target time is set from general pieces of information such as the classification of the product, the material of the blank and the tools can be easily determined even in a case where the cutting working case database has none of the similar working cases.", "Further, in the case of determining the tools in sequence from the largest diameter as a man determines the tools, irrespective of the configuration of the object workpiece, a calculation as to whether the tool is usable or not in sequence from the largest tool among those registered on the tool library, must be performed, however, the tool having the minimum tool diameter can be uniquely obtained from the three-dimensional CAD data of the object workpiece, and, if the tools are determined in a diameter decreasing sequence from the tool having the smallest diameter, the tools and more essentially the working processes can be determined.", "FIGS. 3 and 39 are explanatory diagrams of control of determining the tool and the working process from a reduction time. As shown in the same Figures, the working control device of the invention executes respective steps of a method of determining the tool and the working process from the reduction time in accordance with the working control program (including the tool determining program).", "At first, in step 1, the three-dimensional configuration characteristic extraction unit 12 acquires a final configuration (a configuration of an object workpiece) and a blank configuration from the three-dimensional CAD data of the object workpiece, and acquires an area, as a removal area, into which the final configuration is removed from the blank configuration (namely, a volume of the removal area is obtained by subtracting a volume of the final configuration from a volume of the blank). In the embodiment, the three-dimensional configuration characteristic extraction unit 12 obtains the removal area, however, without being limited to this, only the final configuration is obtained in step 1, the blank configuration is inputted in step 2, and the cutting working condition auto setting unit 14 may acquire the removal area by removing the final configuration from the blank configuration in step 5.", "In step 2, the pre-working input unit 11 accepts an input of pieces of object workpiece information such as a classification of a product, a material of the workpiece, etc.. Note that the cutting working case database is previously stored with a cutting quantity (a reference cutting quantity) per unit time which serves as a reference for determining the tool, mapping to the object workpiece information such as the classification of the product, the material of the workpiece, etc..", "In step 3, the case searching unit 13 searches the cutting working case database and thus obtains a reference value mapping to the classification of the product and the material of the workpiece, as a working case.", "In case this working case is searched out (S4), moving to step 5, the cutting working condition auto setting unit 14 determines, based on this working case, the working conditions, i.e., the tool and the working process.", "FIG. 39 is the chart showing in detail a procedure of determining the tool and the working process in step 5.", "As shown in the same chart, the cutting working condition auto setting unit 14 executes the following steps.", "In step 511, a minimum tool diameter required for the cutting/working is determined based on the information about the usable tool information stored on the tool library and the three-dimensional CAD data. Namely, the minimum concave shape radius dimension is obtained as in the item 2-4 from the three-dimensional CAD data, and, among the diameters of the tools stored on the tool library, a diameter that is equal to or smaller than but most approximate to this dimension is set as the minimum tool diameter.", "The tool library is stored with the tool diameter of the usable tool, the feeding speed, the pitch, the Z-cutting quantity and the cutting quantity per unit time as shown in, e.g., Table 1.", "In step 512, a reduction time of the cutting/working is determined based on the working case (the reference value) searched out by the case searching unit 13. Namely, the reduction time (e.g., 30 min.) is calculated by dividing the value of the removal area by the reference value. This reduction time may be a time difference a between the cutting time Tn and the cutting time Tn-1 and may also be a rate \u00df (a reduction rate: Tn/Tn-1) of the cutting time Tn-1 to the cutting time Tn. Further, in the example, the time difference is determined by calculating the reference value searched out, however, without being limited to this, the reduction time (the time difference a and the reduction rate \u00df) is stored beforehand mapping to the object workpiece information, and the working case searched out by the case searching unit 13 may be determined directly as the reduction time.", "In step 513, a time T1 when the entire removal area is cut by a tool TL1 having the minimum tool diameter, is calculated. That is, the cutting time T1 is obtained by dividing the volume of the removal area by the cutting quantity, per unit time, of the tool TL1.", "In step 514, the tools are added in sequence from the tool having the minimum tool diameter, and the cutting time Tn in the case of effecting the cutting/working with the tools inclusive of the n-th tool, is calculated. The tools to be added, which have diameters larger than the diameter of the tool with the cutting time already calculated, are extracted by every predetermined number of pieces from among the usable tools.", "In this step 514, the cutting time Tn is calculated, wherein the cutting/working for the Z-cutting quantity is performed with the tools inclusive of TLn-1 when the n-th tool is set as TLn, and a time for which the residual cutting/working is effected with the tool TLn is set as the time Tn.", "Table 2 shows volumes cut respectively by the tools TL1 ~ TL8 in the case of performing the working by n-pieces of tools.", "Namely, the cutting time Tn in the case of effecting the cutting/working by each number of pieces is a sum of the time when cut with the tools TL1 ~ TLn-1 by the Z-cutting quantity and the time when the residual cutting is done with the tool TLn.", "In step 515, the cutting time Tn with the tool TLn is compared with the cutting time Tn-1 with the tools TL1 ~ TLn-1, in a case where the time Tn becomes shorter by the reduction time (corresponding to a predetermined value) or above than the time Tn-1, namely, if Tn-1 = a + Tn (or Tn = \u00df X Tn-1), the process (S514) of calculating the cutting time Tn by adding the tool is repeated, and, in case the cutting time Tn does not become shorter by the reduction time or above than the cutting time Tn-1, namely, if Tn-1 < a + Tn (or Tn > \u00df X Tn-1), there moves to step 516.", "Table 4 shows the reduction time (the time difference a and the reduction rate \u00df) in the case of performing the cutting/working with each number of tools.", "In step 516, the using tool is determined from among (n-1)-pieces of tools at a point of time when the time Tn does not shorter by the predetermined value or above than the time Tn-1. That is, if the cutting time T1 is less than a + T2, only the tool TL1 is employed, and, if the cutting time Tn-1 = T5 comes to less than a + T6, the tool is determined from among TL1 ~ TL5. For example, in the example in Table 4, if the time difference a is 30 min. or if the reduction rate \u00df is 10%, the tool is determined from among TL1 ~ TL7.", "Note that the method of determining the using tool from the plurality of tools is arbitrary, all the tools may be used, and a predetermined number of pieces may also be selected. For instance, in the case of selecting three pieces from among n-pieces of tools (n is three or larger in this case), a tool having the minimum diameter, a tool having the maximum diameter and one piece of tool having an intermediate diameter therebetween are selected. Similarly, in the case of selecting four pieces from among the n-pieces of tools, the tool having the minimum diameter, the tool having the maximum diameter and two pieces of tools having the intermediate diameter therebetween are selected.", "In step 517, the working process is determined in sequence from the largest tool diameter among the selected tools. For example, in case this searched-out working tool set is ball end mills having a diameter of 10 mm, a diameter of 6 mm, a diameter of 3 mm and a diameter of 1 mm, a first working process is assigned to the diameter of 10 mm, a second working process is assigned to the diameter of 6 mm, a third working process is assigned to the diameter of 3 mm, and a fourth working process is assigned to the diameter of 1 mm, thus assigning the working processes to the working tools from the largest diameter of the working tool down to the smallest diameter thereof.", "Then, the processes from step 7 onwards are executed by use of the determined tools and the working processes.", "Thus, the tools are added in sequence from the tool TL1 having the minimum tool diameter, the tool Ln when the target time is reached is obtained, and the tools are determined to use TL1 ~ TLn, whereby the target time is set from general pieces of information such as the classification of the product, the material of the blank, etc. and the tool can be easily determined even in a case where the cutting working case database has none of the similar working cases.", "Further, in the case of determining the tools in sequence from the largest diameter as a man determines the tools, irrespective of the configuration of the object workpiece, a calculation as to whether the tool is usable or not in sequence from the largest tool among those registered on the tool library, must be performed, however, the tool having the minimum tool diameter can be uniquely obtained from the three-dimensional CAD data of the object workpiece, and, if the tools are determined in a diameter decreasing sequence from the tool having the smallest diameter, the tools and more essentially the working processes can be determined.", "As described above, according to the embodiment, the working configuration characteristics of how the man has been recognizing the working configuration and determining the cutting process, the using tool, the cutting conditions, etc. from the experiences, are used as the search key to search for the similar working case, the working conditions are determined based on this, and the processes of how the man determines the working conditions as the brain conceives are systematized, thereby enabling the inexperienced person for the cutting/working to perform the cutting/working in safety with the high quality in a way that restrains a scatter in quality, which depends on the know-how and the experiences of other persons.", "Further, the numerical value data are acquired form the actual working phenomena and accumulated as the working cases on the database, and this enables them to be retrieved corresponding to the characteristics of the working configuration, whereby the know-how, which could not be so far left except as a memory of the experienced person, is left as the database and made thus reusable.", "Moreover, as for the object workpiece about which the there is no cutting/working experience, the proper tool and process can be easily determined based on the general pieces of information (the default values) such as the classification of the product, the material of the blank, etc.. Further, it is possible to restrain the scatter in working quality depending on the difference in experience between the operators. Still further, the tool and the process can be efficiently determined by the search starting from the minimum tool diameter."], "tags": ["G06F", "B23Q", "G05B"]}]}